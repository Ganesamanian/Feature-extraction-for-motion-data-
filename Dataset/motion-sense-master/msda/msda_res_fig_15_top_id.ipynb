{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras \n",
    "import keras.backend as K\n",
    "from scipy.signal import resample\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model, load_model, model_from_json \n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, Concatenate,  Dropout \n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: float(majority/count) for cls, count in counter.items()}\n",
    "\n",
    "\n",
    "\n",
    "class Estimator:\n",
    "    l2p = 0.001\n",
    "    @staticmethod\n",
    "    def early_layers(inp, fm = (1,3), hid_act_func=\"relu\"):\n",
    "        # Start\n",
    "        x = Conv2D(32, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # 1\n",
    "        x = Conv2D(32, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def late_layers(inp, num_classes, fm = (1,3), act_func=\"softmax\", hid_act_func=\"relu\", b_name=\"Identifier\"):\n",
    "        # 2\n",
    "        x = Conv2D(32, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        \n",
    "        # End\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(32, kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_classes, activation=act_func, name = b_name)(x)\n",
    "\n",
    "        return x\n",
    "   \n",
    "    @staticmethod\n",
    "    def build(height, width, num_classes, name, fm = (1,3), act_func=\"softmax\",hid_act_func=\"relu\"):\n",
    "        inp = Input(shape=(height, width, 1))\n",
    "        early = Estimator.early_layers(inp, fm, hid_act_func=hid_act_func)\n",
    "        late  = Estimator.late_layers(early, num_classes, fm, act_func=act_func, hid_act_func=hid_act_func)\n",
    "        model = Model(inputs=inp, outputs=late ,name=name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_ds_infos():\n",
    "    \"\"\"\n",
    "    Read the file includes data subject information.\n",
    "    \n",
    "    Data Columns:\n",
    "    0: code [1-24]\n",
    "    1: weight [kg]\n",
    "    2: height [cm]\n",
    "    3: age [years]\n",
    "    4: gender [0:Female, 1:Male]\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame that contains inforamtion about data subjects' attributes \n",
    "    \"\"\" \n",
    "\n",
    "    dss = pd.read_csv(\"data_subjects_info.csv\")\n",
    "    print(\"[INFO] -- Data subjects' information is imported.\")\n",
    "    \n",
    "    return dss\n",
    "\n",
    "def set_data_types(data_types=[\"userAcceleration\"]):\n",
    "    \"\"\"\n",
    "    Select the sensors and the mode to shape the final dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_types: A list of sensor data type from this list: [attitude, gravity, rotationRate, userAcceleration] \n",
    "\n",
    "    Returns:\n",
    "        It returns a list of columns to use for creating time-series from files.\n",
    "    \"\"\"\n",
    "    dt_list = []\n",
    "    for t in data_types:\n",
    "        if t != \"attitude\":\n",
    "            dt_list.append([t+\".x\",t+\".y\",t+\".z\"])\n",
    "        else:\n",
    "            dt_list.append([t+\".roll\", t+\".pitch\", t+\".yaw\"])\n",
    "\n",
    "    return dt_list\n",
    "\n",
    "\n",
    "def creat_time_series(dt_list, act_labels, trial_codes, mode=\"mag\", labeled=True, combine_grav_acc=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dt_list: A list of columns that shows the type of data we want.\n",
    "        act_labels: list of activites\n",
    "        trial_codes: list of trials\n",
    "        mode: It can be \"raw\" which means you want raw data\n",
    "        for every dimention of each data type,\n",
    "        [attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)].\n",
    "        or it can be \"mag\" which means you only want the magnitude for each data type: (x^2+y^2+z^2)^(1/2)\n",
    "        labeled: True, if we want a labeld dataset. False, if we only want sensor values.\n",
    "        combine_grav_acc: True, means adding each axis of gravity to  corresponding axis of userAcceleration.\n",
    "    Returns: \n",
    "        It returns a time-series of sensor data.\n",
    "    \n",
    "    \"\"\"\n",
    "    num_data_cols = len(dt_list) if mode == \"mag\" else len(dt_list*3)\n",
    "\n",
    "    if labeled:\n",
    "        dataset = np.zeros((0,num_data_cols+7)) # \"7\" --> [act, code, weight, height, age, gender, trial] \n",
    "    else:\n",
    "        dataset = np.zeros((0,num_data_cols))\n",
    "        \n",
    "    ds_list = get_ds_infos()\n",
    "    \n",
    "    print(\"[INFO] -- Creating Time-Series\")\n",
    "    for sub_id in ds_list[\"code\"]:\n",
    "        for act_id, act in enumerate(act_labels):\n",
    "            for trial in trial_codes[act_id]:\n",
    "                fname = 'A_DeviceMotion_data/'+act+'_'+str(trial)+'/sub_'+str(int(sub_id))+'.csv'\n",
    "                raw_data = pd.read_csv(fname)\n",
    "                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n",
    "                vals = np.zeros((len(raw_data), num_data_cols))\n",
    "                \n",
    "                if combine_grav_acc:\n",
    "                    raw_data[\"userAcceleration.x\"] = raw_data[\"userAcceleration.x\"].add(raw_data[\"gravity.x\"])\n",
    "                    raw_data[\"userAcceleration.y\"] = raw_data[\"userAcceleration.y\"].add(raw_data[\"gravity.y\"])\n",
    "                    raw_data[\"userAcceleration.z\"] = raw_data[\"userAcceleration.z\"].add(raw_data[\"gravity.z\"])\n",
    "                \n",
    "                for x_id, axes in enumerate(dt_list):\n",
    "                    if mode == \"mag\":\n",
    "                        vals[:,x_id] = (raw_data[axes]**2).sum(axis=1)**0.5        \n",
    "                    else:\n",
    "                        vals[:,x_id*3:(x_id+1)*3] = raw_data[axes].values\n",
    "                    vals = vals[:,:num_data_cols]\n",
    "                if labeled:\n",
    "                    lbls = np.array([[act_id,\n",
    "                            sub_id-1,\n",
    "                            ds_list[\"weight\"][sub_id-1],\n",
    "                            ds_list[\"height\"][sub_id-1],\n",
    "                            ds_list[\"age\"][sub_id-1],\n",
    "                            ds_list[\"gender\"][sub_id-1],\n",
    "                            trial          \n",
    "                           ]]*len(raw_data))\n",
    "                    vals = np.concatenate((vals, lbls), axis=1)\n",
    "                dataset = np.append(dataset,vals, axis=0)\n",
    "    cols = []\n",
    "    for axes in dt_list:\n",
    "        if mode == \"raw\":\n",
    "            cols += axes\n",
    "        else:\n",
    "            cols += [str(axes[0][:-2])]\n",
    "            \n",
    "    if labeled:\n",
    "        cols += [\"act\", \"id\", \"weight\", \"height\", \"age\", \"gender\", \"trial\"]\n",
    "    \n",
    "    dataset = pd.DataFrame(data=dataset, columns=cols)\n",
    "    return dataset\n",
    "#________________________________\n",
    "#________________________________\n",
    "\n",
    "def ts_to_secs(dataset, w, s, standardize = False, **options):\n",
    "    \n",
    "    data = dataset[dataset.columns[:-7]].values    \n",
    "    act_labels = dataset[\"act\"].values\n",
    "    id_labels = dataset[\"id\"].values\n",
    "    trial_labels = dataset[\"trial\"].values\n",
    "\n",
    "    mean = 0\n",
    "    std = 1\n",
    "    if standardize:\n",
    "        ## Standardize each sensorâ€™s data to have a zero mean and unity standard deviation.\n",
    "        ## As usual, we normalize test dataset by training dataset's parameters \n",
    "        if options:\n",
    "            mean = options.get(\"mean\")\n",
    "            std = options.get(\"std\")\n",
    "            print(\"[INFO] -- Test Data has been standardized\")\n",
    "        else:\n",
    "            mean = data.mean(axis=0)\n",
    "            std = data.std(axis=0)\n",
    "            print(\"[INFO] -- Training Data has been standardized: the mean is = \"+str(mean)+\" ; and the std is = \"+str(std))            \n",
    "\n",
    "        data -= mean\n",
    "        data /= std\n",
    "    else:\n",
    "        print(\"[INFO] -- Without Standardization.....\")\n",
    "\n",
    "    ## We want the Rows of matrices show each Feature and the Columns show time points.\n",
    "    data = data.T\n",
    "\n",
    "    m = data.shape[0]   # Data Dimension \n",
    "    ttp = data.shape[1] # Total Time Points\n",
    "    number_of_secs = int(round(((ttp - w)/s)))\n",
    "\n",
    "    ##  Create a 3D matrix for Storing Sections  \n",
    "    secs_data = np.zeros((number_of_secs , m , w ))\n",
    "    act_secs_labels = np.zeros(number_of_secs)\n",
    "    id_secs_labels = np.zeros(number_of_secs)\n",
    "\n",
    "    k=0\n",
    "    for i in range(0 , ttp-w, s):\n",
    "        j = i // s\n",
    "        if j >= number_of_secs:\n",
    "            break\n",
    "        if id_labels[i] != id_labels[i+w-1]: \n",
    "            continue\n",
    "        if act_labels[i] != act_labels[i+w-1]: \n",
    "            continue\n",
    "        if trial_labels[i] != trial_labels[i+w-1]:\n",
    "            continue\n",
    "            \n",
    "        secs_data[k] = data[:, i:i+w]\n",
    "        act_secs_labels[k] = act_labels[i].astype(int)\n",
    "        id_secs_labels[k] = id_labels[i].astype(int)\n",
    "        k = k+1\n",
    "        \n",
    "    secs_data = secs_data[0:k]\n",
    "    act_secs_labels = act_secs_labels[0:k]\n",
    "    id_secs_labels = id_secs_labels[0:k]\n",
    "    return secs_data, act_secs_labels, id_secs_labels, mean, std\n",
    "##________________________________________________________________\n",
    "\n",
    "\n",
    "ACT_LABELS = [\"dws\",\"ups\", \"wlk\", \"jog\", \"std\", \"sit\"]\n",
    "TRIAL_CODES = {\n",
    "    ACT_LABELS[0]:[1,2,11],\n",
    "    ACT_LABELS[1]:[3,4,12],\n",
    "    ACT_LABELS[2]:[7,8,15],\n",
    "    ACT_LABELS[3]:[9,16],\n",
    "    ACT_LABELS[4]:[6,14],\n",
    "    ACT_LABELS[5]:[5,13],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/45305384/5210098\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 9)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 9)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 9)\n",
      "___________________________________________________\n",
      "   rotationRate  userAcceleration  act   id  weight  height   age  gender  \\\n",
      "0      1.370498          1.195847  0.0  0.0   102.0   188.0  46.0     1.0   \n",
      "1      1.141648          1.196990  0.0  0.0   102.0   188.0  46.0     1.0   \n",
      "2      0.372530          1.117437  0.0  0.0   102.0   188.0  46.0     1.0   \n",
      "3      1.049628          1.088320  0.0  0.0   102.0   188.0  46.0     1.0   \n",
      "4      0.921229          1.390551  0.0  0.0   102.0   188.0  46.0     1.0   \n",
      "\n",
      "   trial  \n",
      "0    1.0  \n",
      "1    1.0  \n",
      "2    1.0  \n",
      "3    1.0  \n",
      "4    1.0  \n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278 1.19815844] ; and the std is = [1.42146386 0.70139403]\n",
      "[INFO] -- Test Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 2, 128)\n",
      "[INFO] -- Test Sections:  (13344, 2, 128)\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "results ={}\n",
    "sdt = [\"rotationRate\",\"userAcceleration\"]\n",
    "mode = \"mag\"\n",
    "cga = True # Add gravity to acceleration or not\n",
    "\n",
    "print(\"[INFO] -- Selected sensor data types: \"+str(sdt)+\" -- Mode: \"+str(mode)+\" -- Grav+Acc: \"+str(cga))    \n",
    "act_labels = ACT_LABELS [0:4]\n",
    "\n",
    "print(\"[INFO] -- Selected activites: \"+str(act_labels))    \n",
    "trial_codes = [TRIAL_CODES[act] for act in act_labels]\n",
    "dt_list = set_data_types(sdt)\n",
    "dataset = creat_time_series(dt_list, act_labels, trial_codes, mode=mode, labeled=True, combine_grav_acc = cga)\n",
    "print(\"[INFO] -- Shape of time-Series dataset:\"+str(dataset.shape))    \n",
    "\n",
    "\n",
    "#*****************\n",
    "TRAIN_TEST_TYPE = \"trial\" # \"subject\" or \"trial\"\n",
    "#*****************\n",
    "\n",
    "if TRAIN_TEST_TYPE == \"subject\":\n",
    "    test_ids = [4,9,11,21]\n",
    "    print(\"[INFO] -- Test IDs: \"+str(test_ids))\n",
    "    test_ts = dataset.loc[(dataset['id'].isin(test_ids))]\n",
    "    train_ts = dataset.loc[~(dataset['id'].isin(test_ids))]\n",
    "else:\n",
    "    test_trail = [11,12,13,14,15,16]  \n",
    "    print(\"[INFO] -- Test Trials: \"+str(test_trail))\n",
    "    test_ts = dataset.loc[(dataset['trial'].isin(test_trail))]\n",
    "    train_ts = dataset.loc[~(dataset['trial'].isin(test_trail))]\n",
    "\n",
    "print(\"[INFO] -- Shape of Train Time-Series :\"+str(train_ts.shape))\n",
    "print(\"[INFO] -- Shape of Test Time-Series :\"+str(test_ts.shape))\n",
    "\n",
    "# print(\"___________Train_VAL____________\")\n",
    "# val_trail = [11,12,13,14,15,16]\n",
    "# val_ts = train_ts.loc[(train_ts['trial'].isin(val_trail))]\n",
    "# train_ts = train_ts.loc[~(train_ts['trial'].isin(val_trail))]\n",
    "# print(\"[INFO] -- Training Time-Series :\"+str(train_ts.shape))\n",
    "# print(\"[INFO] -- Validation Time-Series :\"+str(val_ts.shape))\n",
    "\n",
    "print(\"___________________________________________________\")\n",
    "print(train_ts.head())\n",
    "\n",
    "## This Variable Defines the Size of Sliding Window\n",
    "## ( e.g. 100 means in each snapshot we just consider 100 consecutive observations of each sensor) \n",
    "w = 128 # 50 Equals to 1 second for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "## Here We Choose Step Size for Building Diffrent Snapshots from Time-Series Data\n",
    "## ( smaller step size will increase the amount of the instances and higher computational cost may be incurred )\n",
    "s = 10\n",
    "train_data, act_train, id_train, train_mean, train_std = ts_to_secs(train_ts.copy(),\n",
    "                                                                   w,\n",
    "                                                                   s,\n",
    "                                                                   standardize = True)\n",
    "\n",
    "s = 10\n",
    "# val_data, act_val, id_val, val_mean, val_std = ts_to_secs(val_ts.copy(),\n",
    "#                                                           w,\n",
    "#                                                           s,\n",
    "#                                                           standardize = True,\n",
    "#                                                           mean = train_mean, \n",
    "#                                                           std = train_std)\n",
    "\n",
    "s = 10\n",
    "test_data, act_test, id_test, test_mean, test_std = ts_to_secs(test_ts.copy(),\n",
    "                                                              w,\n",
    "                                                              s,\n",
    "                                                              standardize = True,\n",
    "                                                              mean = train_mean, \n",
    "                                                              std = train_std)\n",
    "\n",
    "print(\"[INFO] -- Training Sections: \"+str(train_data.shape))\n",
    "#print(\"[INFO] -- Validation Sections: \"+str(val_data.shape))\n",
    "print(\"[INFO] -- Test Sections:  \"+str(test_data.shape))\n",
    "\n",
    "\n",
    "id_train_labels = to_categorical(id_train)\n",
    "#id_val_labels = to_categorical(id_val)\n",
    "id_test_labels = to_categorical(id_test)\n",
    "\n",
    "act_train_labels = to_categorical(act_train)\n",
    "#act_val_labels = to_categorical(act_val)\n",
    "act_test_labels = to_categorical(act_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, act_train_labels, id_train_labels = shuffle(train_data, act_train_labels, id_train_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bck_train_data = train_data.copy()\n",
    "#bck_val_data = val_data.copy()\n",
    "bck_test_data = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_act_id(sdt, mode, ep, cga, num_sampels):\n",
    "    global bck_train_data, bck_test_data\n",
    "    global act_train_labels,  act_test_labels\n",
    "    ## DownSampling ##\n",
    "    if  num_sampels!= 128:\n",
    "        ds_train_data = bck_train_data.copy()\n",
    "        #ds_val_data = bck_val_data.copy()\n",
    "        ds_test_data = bck_test_data.copy()\n",
    "    \n",
    "        for sens in range(2):\n",
    "            tmp = np.array([resample(x,num_sampels) for x in ds_train_data[:,sens,:]])\n",
    "            ds_train_data[:,sens,:num_sampels] = tmp\n",
    "            \n",
    "#             tmp = np.array([resample(x,num_sampels) for x in ds_val_data[:,sens,:]])\n",
    "#             ds_val_data[:,sens,:num_sampels] = tmp\n",
    "\n",
    "            tmp = np.array([resample(x,num_sampels) for x in ds_test_data[:,sens,:]])\n",
    "            ds_test_data[:,sens,:num_sampels] = tmp \n",
    "\n",
    "        ds_train_data = ds_train_data[:,:,:num_sampels]\n",
    "       # ds_val_data = ds_val_data[:,:,:num_sampels]\n",
    "        ds_test_data = ds_test_data[:,:,:num_sampels]\n",
    "\n",
    "        print(\"[INFO] -- Training Sections:\", ds_train_data.shape)\n",
    "        #print(\"[INFO] -- Validation Sections:\", ds_val_data.shape)\n",
    "        print(\"[INFO] -- Test Sections:\", ds_test_data.shape)\n",
    "\n",
    "        train_data = ds_train_data\n",
    "        #val_data = ds_val_data\n",
    "        test_data = ds_test_data\n",
    "        width = num_sampels\n",
    "    else:\n",
    "        train_data = bck_train_data.copy()\n",
    "        #val_data = bck_val_data.copy()\n",
    "        test_data = bck_test_data.copy()\n",
    "\n",
    "    height = train_data.shape[1]\n",
    "    width = train_data.shape[2]\n",
    "    ## Here we add an extra dimension to the datasets just to be ready for using with Convolution2D\n",
    "    train_data = np.expand_dims(train_data,axis=3)\n",
    "    print(\"[INFO] -- Training Sections:\", train_data.shape)\n",
    "#     val_data = np.expand_dims(val_data,axis=3)\n",
    "#     print(\"[INFO] -- Validation Sections:\", val_data.shape)\n",
    "    test_data = np.expand_dims(test_data,axis=3)\n",
    "    print(\"[INFO] -- Test Sections:\", test_data.shape)\n",
    "\n",
    "   \n",
    "\n",
    "    height = train_data.shape[1]\n",
    "    width = train_data.shape[2]\n",
    "\n",
    "    id_class_numbers = 24\n",
    "    act_class_numbers = 4\n",
    "    fm = (2,5)\n",
    "\n",
    "    print(\"___________________________________________________\")\n",
    "    ## Callbacks\n",
    "    eval_metric= \"val_acc\"    \n",
    "    #eval_metric= \"val_f1_metric\"    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor=eval_metric, mode='max', patience = 7)\n",
    "    filepath=\"XXACT.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor=eval_metric, verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint, early_stop]\n",
    "    ## Callbacks\n",
    "\n",
    "    eval_act = Estimator.build(height, width, id_class_numbers, name =\"EVAL_ACT\", fm=fm, act_func=\"softmax\",hid_act_func=\"relu\")\n",
    "    eval_act.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc',f1_metric])\n",
    "    print(\"Model Size = \"+str(eval_act.count_params()))\n",
    "\n",
    "    eval_act.fit(train_data, id_train_labels,\n",
    "                validation_split = .2,\n",
    "                epochs = ep,\n",
    "                batch_size = 128,\n",
    "                verbose = 0,\n",
    "                class_weight = get_class_weights(np.argmax(id_train_labels,axis=1)),\n",
    "                callbacks = callbacks_list\n",
    "               )\n",
    "\n",
    "    eval_act.load_weights(\"XXACT.best.hdf5\")\n",
    "    eval_act.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc',f1_metric])\n",
    "\n",
    "    result1 = eval_act.evaluate(test_data, id_test_labels, verbose = 2)\n",
    "    act_acc = result1[1].round(4)*100\n",
    "    print(\"***[RESULT]*** ID Accuracy: \"+str(act_acc))\n",
    "\n",
    "    preds = eval_act.predict(test_data)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    conf_mat = confusion_matrix(np.argmax(id_test_labels, axis=1), preds)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"***[RESULT]*** ID  Confusion Matrix\")\n",
    "    print((np.array(conf_mat).diagonal()).round(3)*100)  \n",
    "\n",
    "    f1act = f1_score(np.argmax(id_test_labels, axis=1), preds, average=None).mean()\n",
    "    print(\"***[RESULT]*** ID Averaged F-1 Score : \"+str(f1act))\n",
    "\n",
    "    return f1act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 50 --> Number of Samples: 128\n",
      "[INFO] -- Training Sections: (60059, 2, 128, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 158040\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.33758, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.33758 to 0.46329, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.46329 to 0.65693, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.65693 to 0.80411, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80411 to 0.85331, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85331 to 0.88745, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.88745 to 0.91425, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91425 to 0.92949, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92949 to 0.93815, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.93815 to 0.95246, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95246\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.95246 to 0.95887, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.95887 to 0.96162, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.96162 to 0.96287, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.96287\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.96287 to 0.97036, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.97036\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.97036\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.97036 to 0.97120, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97120\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.97120 to 0.97253, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97253\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97253\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.97253 to 0.97369, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.97369 to 0.97794, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97794\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97794\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97794\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97794\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97794\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97794\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97794\n",
      "***[RESULT]*** ID Accuracy: 93.44\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 91.   99.2  95.   92.   95.1  83.5  93.3  98.5  96.   98.   92.2  96.1\n",
      "  98.8  59.4  94.9  97.6  93.3  79.7  98.7  90.1 100.   96.8  99.7  88. ]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9269825155023431\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 50 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 45 --> Number of Samples: 115\n",
      "[INFO] -- Training Sections: (60059, 2, 115)\n",
      "[INFO] -- Test Sections: (13344, 2, 115)\n",
      "[INFO] -- Training Sections: (60059, 2, 115, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 115, 1)\n",
      "___________________________________________________\n",
      "Model Size = 141656\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.35206, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.35206 to 0.54837, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.54837 to 0.65534, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.65534 to 0.73685, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.73685 to 0.81652, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.81652 to 0.88811, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.88811 to 0.91700, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91700\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.91700 to 0.94814, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94814\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.94814 to 0.95446, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.95446 to 0.96037, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.96037\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.96037 to 0.96379, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.96379\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.96379 to 0.96853, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96853\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.96853\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96853\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.96853\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.96853 to 0.97219, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97219\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.97219\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.97219 to 0.97536, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97536\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.97536 to 0.97561, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97561\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.97561 to 0.97644, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.97644 to 0.97885, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97885\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97885\n",
      "***[RESULT]*** ID Accuracy: 93.07\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[88.7 98.1 97.7 92.9 95.8 82.1 92.6 98.8 96.8 98.9 86.7 92.  98.5 61.8\n",
      " 95.3 98.5 93.8 78.7 99.4 95.3 99.3 97.4 87.1 95.2]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9234928758231943\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 45 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 40 --> Number of Samples: 102\n",
      "[INFO] -- Training Sections: (60059, 2, 102)\n",
      "[INFO] -- Test Sections: (13344, 2, 102)\n",
      "[INFO] -- Training Sections: (60059, 2, 102, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 102, 1)\n",
      "___________________________________________________\n",
      "Model Size = 125272\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.32118, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.32118 to 0.54129, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.54129 to 0.68648, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.68648 to 0.77314, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.77314 to 0.83400, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.83400 to 0.86547, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.86547 to 0.88820, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.88820 to 0.92840, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92840 to 0.92940, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92940 to 0.93856, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93856 to 0.94672, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.94672 to 0.96104, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.96104\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.96104 to 0.96129, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.96129 to 0.96603, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.96603 to 0.96928, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96928\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96928\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.96928 to 0.97128, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97128\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.97128 to 0.97294, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.97294 to 0.97394, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.97394 to 0.97744, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.97744 to 0.97869, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.97869 to 0.98135, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.98135\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.98135\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.98135\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.98135\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.98135\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.98135 to 0.98360, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.98360\n",
      "***[RESULT]*** ID Accuracy: 92.0\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[77.5 99.1 97.  89.  95.3 82.3 93.1 99.4 98.  97.3 86.5 91.1 99.4 39.5\n",
      " 91.2 99.5 93.8 79.4 99.5 99.1 98.6 98.  89.2 96.9]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9093683070554555\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 40 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 35 --> Number of Samples: 89\n",
      "[INFO] -- Training Sections: (60059, 2, 89)\n",
      "[INFO] -- Test Sections: (13344, 2, 89)\n",
      "[INFO] -- Training Sections: (60059, 2, 89, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 89, 1)\n",
      "___________________________________________________\n",
      "Model Size = 117080\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.35856, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.35856 to 0.51557, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.51557 to 0.68806, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.68806 to 0.71337, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71337 to 0.82209, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.82209 to 0.84574, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.84574 to 0.90301, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.90301 to 0.91217, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91217 to 0.93548, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.93548 to 0.94156, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.94156 to 0.94331, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.94331 to 0.95621, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95621\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.95621 to 0.96512, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.96512\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.96512\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.96512 to 0.96961, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96961\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.96961 to 0.97086, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97086\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97086\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97086\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.97086 to 0.97128, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.97128\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.97128 to 0.97677, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97677\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.97677 to 0.97869, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97869\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97869\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97869\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97869\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97869\n",
      "***[RESULT]*** ID Accuracy: 92.75\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 90.3  99.7  98.5  92.3  94.9  86.1  93.6  97.5  89.   98.4  88.6  94.3\n",
      "  94.7  43.6  90.6  99.2  90.3  78.5 100.   96.5  98.9  99.2  95.7  95.7]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.91596956924969\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 35 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 30 --> Number of Samples: 76\n",
      "[INFO] -- Training Sections: (60059, 2, 76)\n",
      "[INFO] -- Test Sections: (13344, 2, 76)\n",
      "[INFO] -- Training Sections: (60059, 2, 76, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 76, 1)\n",
      "___________________________________________________\n",
      "Model Size = 100696\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.39411, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.39411 to 0.56460, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.56460 to 0.65493, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.65493 to 0.75508, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.75508 to 0.84008, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.84008 to 0.85556, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.85556 to 0.89269, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.89269 to 0.91642, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91642 to 0.92249, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92249 to 0.93790, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93790\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.93790 to 0.95346, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95346\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95346\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95346\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95346\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.95346 to 0.96212, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.96212 to 0.96245, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.96245 to 0.96553, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.96553 to 0.96662, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.96662 to 0.96936, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.96936\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.96936\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.96936 to 0.96970, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.96970\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.96970\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.96970 to 0.97344, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97344\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97344\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.97344 to 0.97386, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.97386 to 0.97419, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97419\n",
      "***[RESULT]*** ID Accuracy: 93.62\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[89.4 98.4 98.9 88.3 93.7 87.1 87.4 98.5 95.8 96.8 84.1 88.1 94.7 82.6\n",
      " 82.7 98.3 96.  87.  99.7 94.6 98.5 98.6 99.5 95.4]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9311111765652239\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 30 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] --  For Sample Rate: 25 --> Number of Samples: 64\n",
      "[INFO] -- Training Sections: (60059, 2, 64)\n",
      "[INFO] -- Test Sections: (13344, 2, 64)\n",
      "[INFO] -- Training Sections: (60059, 2, 64, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 64, 1)\n",
      "___________________________________________________\n",
      "Model Size = 92504\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29196, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29196 to 0.49093, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.49093 to 0.66300, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66300 to 0.80977, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80977 to 0.85614, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85614 to 0.89236, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.89236 to 0.89427, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.89427 to 0.93390, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93390\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.93390 to 0.93731, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93731 to 0.95155, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95155\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.95155 to 0.95346, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.95346 to 0.95788, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.95788 to 0.96229, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.96229\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96229\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96229\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.96229 to 0.96578, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96578\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.96578 to 0.96653, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.96653 to 0.96695, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.96695 to 0.96936, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.96936\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.96936\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.96936 to 0.96995, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.96995 to 0.97003, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97003\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97003\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97003\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.97003 to 0.97211, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.97211 to 0.97386, saving model to XXACT.best.hdf5\n",
      "***[RESULT]*** ID Accuracy: 93.06\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[86.9 98.4 98.8 89.7 97.  80.1 89.7 94.6 90.  97.7 82.7 86.8 95.7 64.6\n",
      " 92.7 99.7 96.4 93.1 99.4 95.8 97.5 99.4 98.2 92.3]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.92375520735912\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 25 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] --  For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 20 --> Number of Samples: 51\n",
      "[INFO] -- Training Sections: (60059, 2, 51)\n",
      "[INFO] -- Test Sections: (13344, 2, 51)\n",
      "[INFO] -- Training Sections: (60059, 2, 51, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 51, 1)\n",
      "___________________________________________________\n",
      "Model Size = 76120\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.38953, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.38953 to 0.53854, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.53854 to 0.66175, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66175 to 0.80428, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80428 to 0.83608, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.83608 to 0.86605, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.86605 to 0.89427, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.89427 to 0.91009, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91009 to 0.92349, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92349 to 0.92566, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92566 to 0.93631, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.93631 to 0.93848, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.93848 to 0.94680, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.94680 to 0.95155, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95155\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.95155 to 0.95171, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.95171 to 0.95488, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.95488 to 0.95579, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.95579 to 0.95604, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.95604 to 0.95813, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.95813 to 0.96220, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.96220\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.96220 to 0.96861, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.96861\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.96861\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.96861\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.96861 to 0.96995, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.96995\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.96995 to 0.97128, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97128\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97128\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97128\n",
      "***[RESULT]*** ID Accuracy: 90.95\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[88.  98.8 97.1 81.9 86.  86.7 91.1 94.1 94.2 96.8 78.4 87.9 96.9 57.3\n",
      " 88.8 97.4 90.1 74.  99.  94.5 98.  97.2 98.3 90.9]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9039122146979531\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 20 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 15 --> Number of Samples: 38\n",
      "[INFO] -- Training Sections: (60059, 2, 38)\n",
      "[INFO] -- Test Sections: (13344, 2, 38)\n",
      "[INFO] -- Training Sections: (60059, 2, 38, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 38, 1)\n",
      "___________________________________________________\n",
      "Model Size = 59736\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36630, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.36630 to 0.48077, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.48077 to 0.64594, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.64594 to 0.74451, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.74451 to 0.76474, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.76474 to 0.82676, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.82676 to 0.84657, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.84657 to 0.87746, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87746 to 0.89419, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.89419 to 0.89910, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.89910 to 0.90052, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.90052 to 0.91725, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.91725 to 0.92474, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92474\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.92474 to 0.93348, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93348\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93348\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.93348 to 0.93498, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93498\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.93498 to 0.93523, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.93523 to 0.94181, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.94181 to 0.94505, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.94505 to 0.94830, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.94830\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.94830\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.94830\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.94830 to 0.95022, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.95022\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.95022 to 0.95255, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.95255\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.95255 to 0.95338, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.95338 to 0.95488, saving model to XXACT.best.hdf5\n",
      "***[RESULT]*** ID Accuracy: 91.42\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[88.  98.3 96.1 91.5 88.8 82.7 91.5 92.9 93.2 92.  71.3 86.8 97.8 74.\n",
      " 87.1 99.7 89.5 83.5 98.1 96.2 97.2 94.8 94.6 89.7]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9090178543158732\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 15 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 10 --> Number of Samples: 25\n",
      "[INFO] -- Training Sections: (60059, 2, 25)\n",
      "[INFO] -- Test Sections: (13344, 2, 25)\n",
      "[INFO] -- Training Sections: (60059, 2, 25, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 25, 1)\n",
      "___________________________________________________\n",
      "Model Size = 51544\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.38553, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.38553 to 0.50450, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50450 to 0.60306, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.60306 to 0.65759, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.65759 to 0.72752, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.72752 to 0.78080, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.78080 to 0.79396, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.79396 to 0.81926, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.81926 to 0.82426, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.82426 to 0.85564, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.85564\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.85564 to 0.86980, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.86980 to 0.87329, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.87329 to 0.88636, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.88636 to 0.89352, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.89352 to 0.89602, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.89602 to 0.90668, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.90668 to 0.91059, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.91059 to 0.91866, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.91866\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.91866\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.91866\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.91866 to 0.92150, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.92150 to 0.92258, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.92258 to 0.92408, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.92408 to 0.92416, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.92416\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.92416 to 0.92599, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.92599\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.92599 to 0.92915, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.92915 to 0.93282, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93282\n",
      "***[RESULT]*** ID Accuracy: 86.81\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[78.4 89.8 94.6 90.4 90.9 84.3 83.4 86.4 86.4 88.1 72.5 82.7 95.7 59.7\n",
      " 92.2 95.3 89.7 70.  92.5 84.6 91.1 89.5 90.6 95.7]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8614083439004313\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 10 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- For Sample Rate: 5 --> Number of Samples: 12\n",
      "[INFO] -- Training Sections: (60059, 2, 12)\n",
      "[INFO] -- Test Sections: (13344, 2, 12)\n",
      "[INFO] -- Training Sections: (60059, 2, 12, 1)\n",
      "[INFO] -- Test Sections: (13344, 2, 12, 1)\n",
      "___________________________________________________\n",
      "Model Size = 35160\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27189, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.27189 to 0.42666, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.42666 to 0.47852, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.47852 to 0.52239, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.52239 to 0.57451, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.57451 to 0.59449, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.59449 to 0.63195, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.63195 to 0.64452, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.64452 to 0.64985, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.64985 to 0.67083, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.67083 to 0.67374, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.67374 to 0.68465, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.68465 to 0.69031, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.69031 to 0.69539, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69539\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.69539 to 0.70788, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.70788\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.70788 to 0.71179, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.71179 to 0.72944, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.72944\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.72944\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.72944\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.72944 to 0.73468, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.73468 to 0.74201, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.74201\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.74201\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.74201\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.74201 to 0.74259, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.74259 to 0.74742, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.74742 to 0.74775, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.74775 to 0.74958, saving model to XXACT.best.hdf5\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.74958 to 0.75008, saving model to XXACT.best.hdf5\n",
      "***[RESULT]*** ID Accuracy: 64.37\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[67.1 67.4 73.3 68.  78.8 71.1 62.9 86.  47.8 54.7 53.6 74.7 88.9 19.1\n",
      " 77.1 75.3 45.2 59.5 70.3 60.3 58.8 60.3 44.  84.6]\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.6340079895840439\n"
     ]
    }
   ],
   "source": [
    "#*******************\n",
    "sample_rate = 5 #Hz\n",
    "#*******************\n",
    "num_sampels = (128*sample_rate)//50\n",
    "print(\"[INFO] -- For Sample Rate: \"+str(sample_rate)+\" --> Number of Samples: \"+str(num_sampels))\n",
    "results[sample_rate] = eval_act_id(sdt, mode, ep, cga, num_sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moh",
   "language": "python",
   "name": "moh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

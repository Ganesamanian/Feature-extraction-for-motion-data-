{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras \n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model, load_model, model_from_json \n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, Concatenate,  Dropout \n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: float(majority/count) for cls, count in counter.items()}\n",
    "\n",
    "\n",
    "\n",
    "class Estimator:\n",
    "    l2p = 0.001\n",
    "    @staticmethod\n",
    "    def early_layers(inp, fm = (1,3), hid_act_func=\"relu\"):\n",
    "        # Start\n",
    "        x = Conv2D(64, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # 1\n",
    "        x = Conv2D(64, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def late_layers(inp, num_classes, fm = (1,3), act_func=\"softmax\", hid_act_func=\"relu\", b_name=\"Identifier\"):\n",
    "        # 2\n",
    "        x = Conv2D(32, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # 3\n",
    "        x = Conv2D(32, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # End\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(64, kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_classes, activation=act_func, name = b_name)(x)\n",
    "\n",
    "        return x\n",
    "   \n",
    "    @staticmethod\n",
    "    def build(height, width, num_classes, name, fm = (1,3), act_func=\"softmax\",hid_act_func=\"relu\"):\n",
    "        inp = Input(shape=(height, width, 1))\n",
    "        early = Estimator.early_layers(inp, fm, hid_act_func=hid_act_func)\n",
    "        late  = Estimator.late_layers(early, num_classes, fm, act_func=act_func, hid_act_func=hid_act_func)\n",
    "        model = Model(inputs=inp, outputs=late ,name=name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_ds_infos():\n",
    "    \"\"\"\n",
    "    Read the file includes data subject information.\n",
    "    \n",
    "    Data Columns:\n",
    "    0: code [1-24]\n",
    "    1: weight [kg]\n",
    "    2: height [cm]\n",
    "    3: age [years]\n",
    "    4: gender [0:Female, 1:Male]\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame that contains inforamtion about data subjects' attributes \n",
    "    \"\"\" \n",
    "\n",
    "    dss = pd.read_csv(\"data_subjects_info.csv\")\n",
    "    print(\"[INFO] -- Data subjects' information is imported.\")\n",
    "    \n",
    "    return dss\n",
    "\n",
    "def set_data_types(data_types=[\"userAcceleration\"]):\n",
    "    \"\"\"\n",
    "    Select the sensors and the mode to shape the final dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_types: A list of sensor data type from this list: [attitude, gravity, rotationRate, userAcceleration] \n",
    "\n",
    "    Returns:\n",
    "        It returns a list of columns to use for creating time-series from files.\n",
    "    \"\"\"\n",
    "    dt_list = []\n",
    "    for t in data_types:\n",
    "        if t != \"attitude\":\n",
    "            dt_list.append([t+\".x\",t+\".y\",t+\".z\"])\n",
    "        else:\n",
    "            dt_list.append([t+\".roll\", t+\".pitch\", t+\".yaw\"])\n",
    "\n",
    "    return dt_list\n",
    "\n",
    "\n",
    "def creat_time_series(dt_list, act_labels, trial_codes, mode=\"mag\", labeled=True, combine_grav_acc=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dt_list: A list of columns that shows the type of data we want.\n",
    "        act_labels: list of activites\n",
    "        trial_codes: list of trials\n",
    "        mode: It can be \"raw\" which means you want raw data\n",
    "        for every dimention of each data type,\n",
    "        [attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)].\n",
    "        or it can be \"mag\" which means you only want the magnitude for each data type: (x^2+y^2+z^2)^(1/2)\n",
    "        labeled: True, if we want a labeld dataset. False, if we only want sensor values.\n",
    "        combine_grav_acc: True, means adding each axis of gravity to  corresponding axis of userAcceleration.\n",
    "    Returns: \n",
    "        It returns a time-series of sensor data.\n",
    "    \n",
    "    \"\"\"\n",
    "    num_data_cols = len(dt_list) if mode == \"mag\" else len(dt_list*3)\n",
    "\n",
    "    if labeled:\n",
    "        dataset = np.zeros((0,num_data_cols+7)) # \"7\" --> [act, code, weight, height, age, gender, trial] \n",
    "    else:\n",
    "        dataset = np.zeros((0,num_data_cols))\n",
    "        \n",
    "    ds_list = get_ds_infos()\n",
    "    \n",
    "    print(\"[INFO] -- Creating Time-Series\")\n",
    "    for sub_id in ds_list[\"code\"]:\n",
    "        for act_id, act in enumerate(act_labels):\n",
    "            for trial in trial_codes[act_id]:\n",
    "                fname = 'A_DeviceMotion_data/'+act+'_'+str(trial)+'/sub_'+str(int(sub_id))+'.csv'\n",
    "                raw_data = pd.read_csv(fname)\n",
    "                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n",
    "                vals = np.zeros((len(raw_data), num_data_cols))\n",
    "                \n",
    "                if combine_grav_acc:\n",
    "                    raw_data[\"userAcceleration.x\"] = raw_data[\"userAcceleration.x\"].add(raw_data[\"gravity.x\"])\n",
    "                    raw_data[\"userAcceleration.y\"] = raw_data[\"userAcceleration.y\"].add(raw_data[\"gravity.y\"])\n",
    "                    raw_data[\"userAcceleration.z\"] = raw_data[\"userAcceleration.z\"].add(raw_data[\"gravity.z\"])\n",
    "                \n",
    "                for x_id, axes in enumerate(dt_list):\n",
    "                    if mode == \"mag\":\n",
    "                        vals[:,x_id] = (raw_data[axes]**2).sum(axis=1)**0.5        \n",
    "                    else:\n",
    "                        vals[:,x_id*3:(x_id+1)*3] = raw_data[axes].values\n",
    "                    vals = vals[:,:num_data_cols]\n",
    "                if labeled:\n",
    "                    lbls = np.array([[act_id,\n",
    "                            sub_id-1,\n",
    "                            ds_list[\"weight\"][sub_id-1],\n",
    "                            ds_list[\"height\"][sub_id-1],\n",
    "                            ds_list[\"age\"][sub_id-1],\n",
    "                            ds_list[\"gender\"][sub_id-1],\n",
    "                            trial          \n",
    "                           ]]*len(raw_data))\n",
    "                    vals = np.concatenate((vals, lbls), axis=1)\n",
    "                dataset = np.append(dataset,vals, axis=0)\n",
    "    cols = []\n",
    "    for axes in dt_list:\n",
    "        if mode == \"raw\":\n",
    "            cols += axes\n",
    "        else:\n",
    "            cols += [str(axes[0][:-2])]\n",
    "            \n",
    "    if labeled:\n",
    "        cols += [\"act\", \"id\", \"weight\", \"height\", \"age\", \"gender\", \"trial\"]\n",
    "    \n",
    "    dataset = pd.DataFrame(data=dataset, columns=cols)\n",
    "    return dataset\n",
    "#________________________________\n",
    "#________________________________\n",
    "\n",
    "def ts_to_secs(dataset, w, s, standardize = False, **options):\n",
    "    \n",
    "    data = dataset[dataset.columns[:-7]].values    \n",
    "    act_labels = dataset[\"act\"].values\n",
    "    id_labels = dataset[\"id\"].values\n",
    "    trial_labels = dataset[\"trial\"].values\n",
    "\n",
    "    mean = 0\n",
    "    std = 1\n",
    "    if standardize:\n",
    "        ## Standardize each sensor’s data to have a zero mean and unity standard deviation.\n",
    "        ## As usual, we normalize test dataset by training dataset's parameters \n",
    "        if options:\n",
    "            mean = options.get(\"mean\")\n",
    "            std = options.get(\"std\")\n",
    "            print(\"[INFO] -- Test/Val Data has been standardized\")\n",
    "        else:\n",
    "            mean = data.mean(axis=0)\n",
    "            std = data.std(axis=0)\n",
    "            print(\"[INFO] -- Training Data has been standardized: the mean is = \"+str(mean)+\" ; and the std is = \"+str(std))            \n",
    "\n",
    "        data -= mean\n",
    "        data /= std\n",
    "    else:\n",
    "        print(\"[INFO] -- Without Standardization.....\")\n",
    "\n",
    "    ## We want the Rows of matrices show each Feature and the Columns show time points.\n",
    "    data = data.T\n",
    "\n",
    "    m = data.shape[0]   # Data Dimension \n",
    "    ttp = data.shape[1] # Total Time Points\n",
    "    number_of_secs = int(round(((ttp - w)/s)))\n",
    "\n",
    "    ##  Create a 3D matrix for Storing Sections  \n",
    "    secs_data = np.zeros((number_of_secs , m , w ))\n",
    "    act_secs_labels = np.zeros(number_of_secs)\n",
    "    id_secs_labels = np.zeros(number_of_secs)\n",
    "\n",
    "    k=0\n",
    "    for i in range(0 , ttp-w, s):\n",
    "        j = i // s\n",
    "        if j >= number_of_secs:\n",
    "            break\n",
    "        if id_labels[i] != id_labels[i+w-1]: \n",
    "            continue\n",
    "        if act_labels[i] != act_labels[i+w-1]: \n",
    "            continue\n",
    "        if trial_labels[i] != trial_labels[i+w-1]:\n",
    "            continue\n",
    "            \n",
    "        secs_data[k] = data[:, i:i+w]\n",
    "        act_secs_labels[k] = act_labels[i].astype(int)\n",
    "        id_secs_labels[k] = id_labels[i].astype(int)\n",
    "        k = k+1\n",
    "        \n",
    "    secs_data = secs_data[0:k]\n",
    "    act_secs_labels = act_secs_labels[0:k]\n",
    "    id_secs_labels = id_secs_labels[0:k]\n",
    "    return secs_data, act_secs_labels, id_secs_labels, mean, std\n",
    "##________________________________________________________________\n",
    "\n",
    "\n",
    "ACT_LABELS = [\"dws\",\"ups\", \"wlk\", \"jog\", \"std\", \"sit\"]\n",
    "TRIAL_CODES = {\n",
    "    ACT_LABELS[0]:[1,2,11],\n",
    "    ACT_LABELS[1]:[3,4,12],\n",
    "    ACT_LABELS[2]:[7,8,15],\n",
    "    ACT_LABELS[3]:[9,16],\n",
    "    ACT_LABELS[4]:[6,14],\n",
    "    ACT_LABELS[5]:[5,13],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/45305384/5210098\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def eval_id(sdt, mode, ep, cga):\n",
    "\n",
    "    print(\"[INFO] -- Selected sensor data types: \"+str(sdt)+\" -- Mode: \"+str(mode)+\" -- Grav+Acc: \"+str(cga))    \n",
    "    act_labels = ACT_LABELS [0:4]\n",
    "\n",
    "    print(\"[INFO] -- Selected activites: \"+str(act_labels))    \n",
    "    trial_codes = [TRIAL_CODES[act] for act in act_labels]\n",
    "    dt_list = set_data_types(sdt)\n",
    "    dataset = creat_time_series(dt_list, act_labels, trial_codes, mode=mode, labeled=True, combine_grav_acc = cga)\n",
    "    print(\"[INFO] -- Shape of time-Series dataset:\"+str(dataset.shape))    \n",
    "\n",
    "\n",
    "    #*****************\n",
    "    TRAIN_TEST_TYPE = \"trial\" # \"subject\" or \"trial\"\n",
    "    #*****************\n",
    "\n",
    "    if TRAIN_TEST_TYPE == \"subject\":\n",
    "        test_ids = [4,9,11,21]\n",
    "        print(\"[INFO] -- Test IDs: \"+str(test_ids))\n",
    "        test_ts = dataset.loc[(dataset['id'].isin(test_ids))]\n",
    "        train_ts = dataset.loc[~(dataset['id'].isin(test_ids))]\n",
    "    else:\n",
    "        test_trail = [11,12,13,14,15,16]  \n",
    "        print(\"[INFO] -- Test Trials: \"+str(test_trail))\n",
    "        test_ts = dataset.loc[(dataset['trial'].isin(test_trail))]\n",
    "        train_ts = dataset.loc[~(dataset['trial'].isin(test_trail))]\n",
    "\n",
    "    print(\"[INFO] -- Shape of Train Time-Series :\"+str(train_ts.shape))\n",
    "    print(\"[INFO] -- Shape of Test Time-Series :\"+str(test_ts.shape))\n",
    "    \n",
    "    print(\"___________________________________________________\")\n",
    "\n",
    "    ## This Variable Defines the Size of Sliding Window\n",
    "    ## ( e.g. 100 means in each snapshot we just consider 100 consecutive observations of each sensor) \n",
    "    w = 128 # 50 Equals to 1 second for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "    ## Here We Choose Step Size for Building Diffrent Snapshots from Time-Series Data\n",
    "    ## ( smaller step size will increase the amount of the instances and higher computational cost may be incurred )\n",
    "    s = 10\n",
    "    train_data, act_train, id_train, train_mean, train_std = ts_to_secs(train_ts.copy(),\n",
    "                                                                       w,\n",
    "                                                                       s,\n",
    "                                                                       standardize = True)\n",
    "    \n",
    "   \n",
    "    s = 10\n",
    "    test_data, act_test, id_test, test_mean, test_std = ts_to_secs(test_ts.copy(),\n",
    "                                                                  w,\n",
    "                                                                  s,\n",
    "                                                                  standardize = True,\n",
    "                                                                  mean = train_mean, \n",
    "                                                                  std = train_std)\n",
    "    \n",
    "    print(\"[INFO] -- Training Sections: \"+str(train_data.shape))\n",
    "    print(\"[INFO] -- Test Sections:  \"+str(test_data.shape))\n",
    "\n",
    "\n",
    "    id_train_labels = to_categorical(id_train)\n",
    "    id_test_labels = to_categorical(id_test)\n",
    "    \n",
    "    act_train_labels = to_categorical(act_train)\n",
    "    act_test_labels = to_categorical(act_test)\n",
    "    \n",
    "    ## Here we add an extra dimension to the datasets just to be ready for using with Convolution2D\n",
    "    train_data = np.expand_dims(train_data,axis=3)\n",
    "    print(\"[INFO] -- Training Sections:\"+str(train_data.shape))\n",
    "\n",
    "    test_data = np.expand_dims(test_data,axis=3)\n",
    "    print(\"[INFO] -- Test Sections:\"+str(test_data.shape))\n",
    "\n",
    "    height = train_data.shape[1]\n",
    "    width = train_data.shape[2]\n",
    "\n",
    "    id_class_numbers = 24\n",
    "    act_class_numbers = 4\n",
    "    fm = (1,5)\n",
    "\n",
    "    print(\"___________________________________________________\")\n",
    "    ## Callbacks\n",
    "    #eval_metric= \"val_acc\"\n",
    "    eval_metric= \"val_f1_metric\"    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor=eval_metric, mode='max', patience = 7)\n",
    "    filepath=\"MID.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor=eval_metric, verbose=0, save_best_only=True, mode='max')\n",
    "    callbacks_list = [early_stop,\n",
    "                      checkpoint\n",
    "                     ]\n",
    "    ## Callbacks\n",
    "    eval_id = Estimator.build(height, width, id_class_numbers, name =\"EVAL_ID\", fm=fm, act_func=\"softmax\",hid_act_func=\"relu\")\n",
    "    eval_id.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc', f1_metric])\n",
    "    print(\"Model Size = \"+str(eval_id.count_params()))\n",
    "\n",
    "    eval_id.fit(train_data, id_train_labels,\n",
    "                validation_data = (test_data, id_test_labels),\n",
    "                epochs = ep,\n",
    "                batch_size = 128,\n",
    "                verbose = 0,\n",
    "                class_weight = get_class_weights(np.argmax(id_train_labels,axis=1)),\n",
    "                callbacks = callbacks_list\n",
    "               )\n",
    "\n",
    "    eval_id.load_weights(\"MID.best.hdf5\")\n",
    "    eval_id.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc',f1_metric])\n",
    "\n",
    "    result1 = eval_id.evaluate(test_data, id_test_labels, verbose = 2)\n",
    "    id_acc = result1[1]\n",
    "    print(\"***[RESULT]*** ID Accuracy: \"+str(id_acc))\n",
    "    rf1 = result1[2].round(4)*100\n",
    "    print(\"***[RESULT]*** ID F1: \"+str(rf1))\n",
    "    \n",
    "    preds = eval_id.predict(test_data)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    conf_mat = confusion_matrix(np.argmax(id_test_labels, axis=1), preds)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"***[RESULT]*** ID  Confusion Matrix\")\n",
    "    print((np.array(conf_mat).diagonal()).round(3)*100)  \n",
    "    \n",
    "    d_test_ids = [4,9,11,21]\n",
    "    to_avg = 0\n",
    "    for i in range(len(d_test_ids)):\n",
    "        true_positive = conf_mat[d_test_ids[i],d_test_ids[i]]\n",
    "        print(\"True Positive Rate for \"+str(d_test_ids[i])+\" : \"+str(true_positive*100))\n",
    "        to_avg+=true_positive\n",
    "    atp = to_avg/len(d_test_ids)    \n",
    "    print(\"Average TP:\"+str(atp*100))    \n",
    "    \n",
    "    f1id = f1_score(np.argmax(id_test_labels, axis=1), preds, average=None).mean()\n",
    "    print(\"***[RESULT]*** ID Averaged F-1 Score : \"+str(f1id))\n",
    "    \n",
    "    return [round(id_acc,4), round(f1id,4), round(atp,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: mag -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278] ; and the std is = [1.42146386]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8687799760191847\n",
      "***[RESULT]*** ID F1: 86.37\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[71.3 99.4 91.7 95.  88.1 85.1 87.8 76.5 77.8 88.1 81.  86.5 95.  75.5\n",
      " 81.6 95.9 88.3 66.2 81.5 84.1 93.1 96.  94.3 88.9]\n",
      "True Positive Rate for 4 : 88.13953488372093\n",
      "True Positive Rate for 9 : 88.09946714031972\n",
      "True Positive Rate for 11 : 86.45276292335116\n",
      "True Positive Rate for 21 : 96.03174603174604\n",
      "Average TP:89.68087774478445\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8661190556894892\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: mag -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278] ; and the std is = [1.42146386]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8428507194244604\n",
      "***[RESULT]*** ID F1: 83.57\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[78.4 98.4 96.4 91.8 86.7 83.5 80.  63.3 71.  91.1 75.6 86.3 97.2 61.\n",
      " 78.  96.2 75.  68.7 85.6 83.  93.2 95.  83.2 87.7]\n",
      "True Positive Rate for 4 : 86.74418604651163\n",
      "True Positive Rate for 9 : 91.1190053285968\n",
      "True Positive Rate for 11 : 86.27450980392157\n",
      "True Positive Rate for 21 : 95.03968253968253\n",
      "Average TP:89.79434592967814\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8376911152398089\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: mag -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278] ; and the std is = [1.42146386]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.856339928057554\n",
      "***[RESULT]*** ID F1: 85.21\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[70.6 97.3 83.3 86.1 83.  79.9 93.1 92.1 80.8 85.6 86.5 80.6 94.4 73.8\n",
      " 84.1 92.5 87.9 71.8 67.4 86.8 94.2 94.4 90.3 83.2]\n",
      "True Positive Rate for 4 : 83.02325581395348\n",
      "True Positive Rate for 9 : 85.61278863232683\n",
      "True Positive Rate for 11 : 80.57040998217468\n",
      "True Positive Rate for 21 : 94.44444444444444\n",
      "Average TP:85.91272471822487\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8520730708032556\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: mag -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278] ; and the std is = [1.42146386]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8696043165467626\n",
      "***[RESULT]*** ID F1: 86.21\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[80.2 98.9 93.7 87.7 90.5 89.2 87.7 82.1 83.6 88.1 85.5 91.1 93.5 51.2\n",
      " 83.5 97.4 81.7 67.8 81.5 88.9 92.4 98.  88.5 87.7]\n",
      "True Positive Rate for 4 : 90.46511627906978\n",
      "True Positive Rate for 9 : 88.09946714031972\n",
      "True Positive Rate for 11 : 91.0873440285205\n",
      "True Positive Rate for 21 : 98.01587301587301\n",
      "Average TP:91.91695011594577\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8617920403510498\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: mag -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278] ; and the std is = [1.42146386]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8554406474820144\n",
      "***[RESULT]*** ID F1: 84.74000000000001\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[74.9 97.5 93.2 92.7 88.8 76.5 91.6 78.9 81.6 87.4 79.1 89.8 93.2 59.2\n",
      " 87.3 98.  73.2 65.8 66.7 87.9 93.8 95.4 93.4 86.9]\n",
      "True Positive Rate for 4 : 88.83720930232558\n",
      "True Positive Rate for 9 : 87.38898756660745\n",
      "True Positive Rate for 11 : 89.83957219251337\n",
      "True Positive Rate for 21 : 95.43650793650794\n",
      "Average TP:90.37556924948859\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8522158533718187\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"rotationRate\"]\n",
    "mode = \"mag\"\n",
    "ep = 40\n",
    "cga = False # Add gravity to acceleration or not\n",
    "for i in range(5):\n",
    "    results[str(sdt)+\"--\"+str(mode)+\"--\"+str(cga)+\"--\"+str(i)] = eval_id(sdt, mode, ep, cga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: raw -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [0.00676741 0.02878308 0.02359966] ; and the std is = [1.74135109 1.64053436 1.08396877]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9426708633093526\n",
      "***[RESULT]*** ID F1: 94.23\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 95.6 100.   99.7  90.7 100.   97.6  89.   63.9  96.8  98.9  97.9  94.8\n",
      " 100.   65.3  89.6  99.5  98.   99.5 100.   98.6  98.7  97.4  92.2  99.4]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 98.93428063943162\n",
      "True Positive Rate for 11 : 94.8306595365419\n",
      "True Positive Rate for 21 : 97.42063492063492\n",
      "Average TP:97.79639377415211\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9424289110626735\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: raw -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [0.00676741 0.02878308 0.02359966] ; and the std is = [1.74135109 1.64053436 1.08396877]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9459682254196643\n",
      "***[RESULT]*** ID F1: 94.38\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 97.2 100.  100.   98.6 100.   97.   71.4  70.4  97.2 100.  100.   95.4\n",
      " 100.   64.2  94.1  98.3  99.4  99.8  99.8  98.8  98.   99.8  94.2  97.7]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 100.0\n",
      "True Positive Rate for 11 : 95.36541889483065\n",
      "True Positive Rate for 21 : 99.8015873015873\n",
      "Average TP:98.79175154910449\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9444730432088009\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: raw -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [0.00676741 0.02878308 0.02359966] ; and the std is = [1.74135109 1.64053436 1.08396877]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9250599520383693\n",
      "***[RESULT]*** ID F1: 92.4\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 88.5 100.   93.4  98.9  99.8  98.2  54.7  72.4  98.2  99.8  98.1  90.9\n",
      " 100.   60.5  85.5  99.8  98.8  99.6 100.   95.7  99.2  98.   91.8  98.3]\n",
      "True Positive Rate for 4 : 99.76744186046511\n",
      "True Positive Rate for 9 : 99.82238010657194\n",
      "True Positive Rate for 11 : 90.9090909090909\n",
      "True Positive Rate for 21 : 98.01587301587301\n",
      "Average TP:97.12869647300025\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9245642140496729\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: raw -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [0.00676741 0.02878308 0.02359966] ; and the std is = [1.74135109 1.64053436 1.08396877]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9343525179856115\n",
      "***[RESULT]*** ID F1: 93.13\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 90.8 100.   99.8  98.1 100.   98.8  75.   48.9  96.4  97.7  99.8  95.\n",
      " 100.   61.2  90.4  99.2  99.6 100.  100.   99.5  97.7 100.   97.7  98.6]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 97.69094138543517\n",
      "True Positive Rate for 11 : 95.00891265597147\n",
      "True Positive Rate for 21 : 100.0\n",
      "Average TP:98.17496351035166\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9324872919486719\n",
      "[INFO] -- Selected sensor data types: ['rotationRate'] -- Mode: raw -- Grav+Acc: False\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [0.00676741 0.02878308 0.02359966] ; and the std is = [1.74135109 1.64053436 1.08396877]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9327038369304557\n",
      "***[RESULT]*** ID F1: 93.24\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 98.6 100.  100.   97.  100.   97.6  76.2  41.5  96.   99.3 100.   94.7\n",
      "  99.7  65.9  92.2  99.1 100.   99.8  99.8  98.3  95.5 100.   94.8  99.7]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 99.28952042628775\n",
      "True Positive Rate for 11 : 94.6524064171123\n",
      "True Positive Rate for 21 : 100.0\n",
      "Average TP:98.48548171085001\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9324549486716581\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"rotationRate\"]\n",
    "mode = \"raw\"\n",
    "ep = 40\n",
    "cga = False # Add gravity to acceleration or not\n",
    "for i in range(5):\n",
    "    results[str(sdt)+\"--\"+str(mode)+\"--\"+str(cga)+\"--\"+str(i)] = eval_id(sdt, mode, ep, cga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['rotationRate']--mag--False--0\": [0.8688, 0.8661, 0.8968],\n",
       " \"['rotationRate']--mag--False--1\": [0.8429, 0.8377, 0.8979],\n",
       " \"['rotationRate']--mag--False--2\": [0.8563, 0.8521, 0.8591],\n",
       " \"['rotationRate']--mag--False--3\": [0.8696, 0.8618, 0.9192],\n",
       " \"['rotationRate']--mag--False--4\": [0.8554, 0.8522, 0.9038],\n",
       " \"['rotationRate']--raw--False--0\": [0.9427, 0.9424, 0.978],\n",
       " \"['rotationRate']--raw--False--1\": [0.946, 0.9445, 0.9879],\n",
       " \"['rotationRate']--raw--False--2\": [0.9251, 0.9246, 0.9713],\n",
       " \"['rotationRate']--raw--False--3\": [0.9344, 0.9325, 0.9817],\n",
       " \"['rotationRate']--raw--False--4\": [0.9327, 0.9325, 0.9849]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [1.19815844] ; and the std is = [0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8779976019184652\n",
      "***[RESULT]*** ID F1: 87.22\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[76.3 93.5 94.3 86.3 83.7 74.5 89.8 96.9 92.2 92.2 71.1 87.3 90.1 32.3\n",
      " 82.  95.1 90.1 92.  97.2 92.2 97.9 97.8 81.5 96.6]\n",
      "True Positive Rate for 4 : 83.72093023255815\n",
      "True Positive Rate for 9 : 92.1847246891652\n",
      "True Positive Rate for 11 : 87.34402852049911\n",
      "True Positive Rate for 21 : 97.81746031746032\n",
      "Average TP:90.2667859399207\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8632631976169179\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [1.19815844] ; and the std is = [0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8872152278177458\n",
      "***[RESULT]*** ID F1: 87.91\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[81.1 97.2 92.5 86.3 89.1 76.9 85.6 96.9 93.2 87.7 81.5 84.8 95.  44.5\n",
      " 71.6 94.4 92.3 90.6 96.9 94.3 99.3 94.  91.4 90.3]\n",
      "True Positive Rate for 4 : 89.06976744186046\n",
      "True Positive Rate for 9 : 87.74422735346359\n",
      "True Positive Rate for 11 : 84.84848484848484\n",
      "True Positive Rate for 21 : 94.04761904761905\n",
      "Average TP:88.92752467285699\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8761227862027668\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [1.19815844] ; and the std is = [0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8863908872901679\n",
      "***[RESULT]*** ID F1: 88.05\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[77.9 96.6 95.3 78.1 85.6 84.1 83.9 92.4 95.2 92.2 65.4 90.9 95.  62.3\n",
      " 73.3 97.4 79.2 91.7 98.4 91.3 95.5 89.5 98.9 95.2]\n",
      "True Positive Rate for 4 : 85.5813953488372\n",
      "True Positive Rate for 9 : 92.1847246891652\n",
      "True Positive Rate for 11 : 90.9090909090909\n",
      "True Positive Rate for 21 : 89.48412698412699\n",
      "Average TP:89.53983448280508\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8776687976998061\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [1.19815844] ; and the std is = [0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8785971223021583\n",
      "***[RESULT]*** ID F1: 87.21\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 78.6  94.4  90.7  81.7  75.8  81.5  88.   93.7  92.   95.2  70.6  85.4\n",
      "  90.4  60.1  73.5  93.6  87.5  91.5 100.   93.9  94.2  96.   85.4  94.9]\n",
      "True Positive Rate for 4 : 75.81395348837209\n",
      "True Positive Rate for 9 : 95.20426287744228\n",
      "True Positive Rate for 11 : 85.38324420677363\n",
      "True Positive Rate for 21 : 96.03174603174604\n",
      "Average TP:88.10830165108351\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8714816123809531\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 8)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 8)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 8)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [1.19815844] ; and the std is = [0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 1, 128)\n",
      "[INFO] -- Test Sections:  (13344, 1, 128)\n",
      "[INFO] -- Training Sections:(60059, 1, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 1, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 122200\n",
      "***[RESULT]*** ID Accuracy: 0.8828687050359713\n",
      "***[RESULT]*** ID F1: 87.72\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[87.4 96.9 95.2 89.3 85.6 80.1 86.7 93.5 96.6 96.1 73.7 82.4 94.7 29.5\n",
      " 79.6 95.1 93.7 87.5 94.6 93.4 98.9 96.2 80.9 87.7]\n",
      "True Positive Rate for 4 : 85.5813953488372\n",
      "True Positive Rate for 9 : 96.0923623445826\n",
      "True Positive Rate for 11 : 82.35294117647058\n",
      "True Positive Rate for 21 : 96.23015873015873\n",
      "Average TP:90.06421440001228\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.8675925381639025\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"userAcceleration\"]\n",
    "mode = \"mag\"\n",
    "ep = 40\n",
    "cga = True # Add gravity to acceleration or not\n",
    "for i in range(5):\n",
    "    results[str(sdt)+\"--\"+str(mode)+\"--\"+str(cga)+\"--\"+str(i)] = eval_id(sdt, mode, ep, cga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['userAcceleration']--mag--True--0\": [0.878, 0.8633, 0.9027],\n",
       " \"['userAcceleration']--mag--True--1\": [0.8872, 0.8761, 0.8893],\n",
       " \"['userAcceleration']--mag--True--2\": [0.8864, 0.8777, 0.8954],\n",
       " \"['userAcceleration']--mag--True--3\": [0.8786, 0.8715, 0.8811],\n",
       " \"['userAcceleration']--mag--True--4\": [0.8829, 0.8676, 0.9006]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.02367904  0.95806826 -0.05104623] ; and the std is = [0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9224370503597122\n",
      "***[RESULT]*** ID F1: 92.25\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 63.4  99.9  97.9  93.1 100.   96.8  53.5  73.6  97.4  98.9  97.6  95.7\n",
      " 100.   75.5  93.3  98.9  94.6 100.   86.7 100.   98.7  98.2  98.3  99.4]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 98.93428063943162\n",
      "True Positive Rate for 11 : 95.72192513368985\n",
      "True Positive Rate for 21 : 98.21428571428571\n",
      "Average TP:98.2176228718518\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9197941176289994\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.02367904  0.95806826 -0.05104623] ; and the std is = [0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9288069544364509\n",
      "***[RESULT]*** ID F1: 92.9\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 57.9 100.   97.9  95.9 100.   99.   53.   71.9  85.4 100.   94.8  95.7\n",
      " 100.   96.1  97.1  99.4  97.2  99.8  92.9  99.7  97.3  99.8  97.7  99.4]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 100.0\n",
      "True Positive Rate for 11 : 95.72192513368985\n",
      "True Positive Rate for 21 : 99.8015873015873\n",
      "Average TP:98.88087810881927\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.929605296860835\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.02367904  0.95806826 -0.05104623] ; and the std is = [0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9276828537170264\n",
      "***[RESULT]*** ID F1: 92.73\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 60.5 100.   97.6  88.  100.   98.   68.5  71.6  96.2 100.   98.1  93.2\n",
      " 100.   73.1  94.7 100.   96.6  99.5  96.1  99.1  94.9  98.6  99.1  99.7]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 100.0\n",
      "True Positive Rate for 11 : 93.22638146167557\n",
      "True Positive Rate for 21 : 98.61111111111111\n",
      "Average TP:97.95937314319667\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9244424382727164\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.02367904  0.95806826 -0.05104623] ; and the std is = [0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9258093525179856\n",
      "***[RESULT]*** ID F1: 92.56\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 62.8 100.   99.4  96.1  99.5  98.2  52.2  69.9  96.8  99.8  92.4  96.3\n",
      " 100.   85.2  92.   99.2  95.6 100.   92.   99.3  96.2  97.6  99.5  99.7]\n",
      "True Positive Rate for 4 : 99.53488372093024\n",
      "True Positive Rate for 9 : 99.82238010657194\n",
      "True Positive Rate for 11 : 96.2566844919786\n",
      "True Positive Rate for 21 : 97.61904761904762\n",
      "Average TP:98.3082489846321\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9240084516904764\n",
      "[INFO] -- Selected sensor data types: ['userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 10)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 10)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 10)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.02367904  0.95806826 -0.05104623] ; and the std is = [0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 3, 128)\n",
      "[INFO] -- Test Sections:  (13344, 3, 128)\n",
      "[INFO] -- Training Sections:(60059, 3, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 3, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 253272\n",
      "***[RESULT]*** ID Accuracy: 0.9274580335731415\n",
      "***[RESULT]*** ID F1: 92.73\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 56.3 100.   88.9  90.1 100.   98.   81.4  64.4  94.  100.   88.6  96.8\n",
      "  99.7  78.5  97.1  99.8  98.8 100.   99.4  96.5  95.6 100.   98.3  99.1]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 100.0\n",
      "True Positive Rate for 11 : 96.79144385026738\n",
      "True Positive Rate for 21 : 100.0\n",
      "Average TP:99.19786096256684\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9254639638126179\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"userAcceleration\"]\n",
    "mode = \"raw\"\n",
    "ep = 40\n",
    "cga = True # Add gravity to acceleration or not\n",
    "for i in range(5):\n",
    "    results[str(sdt)+\"--\"+str(mode)+\"--\"+str(cga)+\"--\"+str(i)] = eval_id(sdt, mode, ep, cga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['userAcceleration']--mag--True--0\": [0.878, 0.8633, 0.9027],\n",
       " \"['userAcceleration']--mag--True--1\": [0.8872, 0.8761, 0.8893],\n",
       " \"['userAcceleration']--mag--True--2\": [0.8864, 0.8777, 0.8954],\n",
       " \"['userAcceleration']--mag--True--3\": [0.8786, 0.8715, 0.8811],\n",
       " \"['userAcceleration']--mag--True--4\": [0.8829, 0.8676, 0.9006],\n",
       " \"['userAcceleration']--raw--True--0\": [0.9224, 0.9198, 0.9822],\n",
       " \"['userAcceleration']--raw--True--1\": [0.9288, 0.9296, 0.9888],\n",
       " \"['userAcceleration']--raw--True--2\": [0.9277, 0.9244, 0.9796],\n",
       " \"['userAcceleration']--raw--True--3\": [0.9258, 0.924, 0.9831],\n",
       " \"['userAcceleration']--raw--True--4\": [0.9275, 0.9255, 0.992]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 9)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 9)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 9)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278 1.19815844] ; and the std is = [1.42146386 0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 2, 128)\n",
      "[INFO] -- Test Sections:  (13344, 2, 128)\n",
      "[INFO] -- Training Sections:(60059, 2, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 2, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 187736\n",
      "***[RESULT]*** ID Accuracy: 0.9230365707434053\n",
      "***[RESULT]*** ID F1: 92.17999999999999\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[74.7 98.8 95.  91.8 93.7 84.7 96.1 97.4 95.6 98.4 74.2 93.9 97.2 49.\n",
      " 90.4 99.4 95.8 91.9 98.5 94.3 99.  98.6 93.4 88.9]\n",
      "True Positive Rate for 4 : 93.72093023255815\n",
      "True Positive Rate for 9 : 98.40142095914743\n",
      "True Positive Rate for 11 : 93.93939393939394\n",
      "True Positive Rate for 21 : 98.61111111111111\n",
      "Average TP:96.16821406055266\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9114187439044757\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 9)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 9)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 9)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278 1.19815844] ; and the std is = [1.42146386 0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 2, 128)\n",
      "[INFO] -- Test Sections:  (13344, 2, 128)\n",
      "[INFO] -- Training Sections:(60059, 2, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 2, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 187736\n",
      "***[RESULT]*** ID Accuracy: 0.9313549160671463\n",
      "***[RESULT]*** ID F1: 92.9\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[87.8 99.5 97.7 90.9 97.7 85.7 91.6 97.1 91.6 97.2 82.2 91.8 98.8 66.4\n",
      " 84.3 98.5 95.2 88.1 99.8 92.5 99.7 98.  97.1 88.6]\n",
      "True Positive Rate for 4 : 97.67441860465115\n",
      "True Positive Rate for 9 : 97.15808170515098\n",
      "True Positive Rate for 11 : 91.80035650623886\n",
      "True Positive Rate for 21 : 98.01587301587301\n",
      "Average TP:96.1621824579785\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.924153792706694\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 9)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 9)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 9)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278 1.19815844] ; and the std is = [1.42146386 0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 2, 128)\n",
      "[INFO] -- Test Sections:  (13344, 2, 128)\n",
      "[INFO] -- Training Sections:(60059, 2, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 2, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 187736\n",
      "***[RESULT]*** ID Accuracy: 0.9392236211031175\n",
      "***[RESULT]*** ID F1: 93.78999999999999\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 85.7 100.   97.9  90.4  89.3  88.4  87.2  95.4  97.   98.4  83.4  92.7\n",
      "  92.9  74.8  91.2  99.5  95.   93.9  99.8  97.6  99.   99.2  94.6  94.3]\n",
      "True Positive Rate for 4 : 89.30232558139535\n",
      "True Positive Rate for 9 : 98.40142095914743\n",
      "True Positive Rate for 11 : 92.6916221033868\n",
      "True Positive Rate for 21 : 99.20634920634922\n",
      "Average TP:94.90042946256969\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9338696272527999\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 9)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 9)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 9)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278 1.19815844] ; and the std is = [1.42146386 0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 2, 128)\n",
      "[INFO] -- Test Sections:  (13344, 2, 128)\n",
      "[INFO] -- Training Sections:(60059, 2, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 2, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 187736\n",
      "***[RESULT]*** ID Accuracy: 0.938923860911271\n",
      "***[RESULT]*** ID F1: 93.7\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[82.3 99.8 99.5 89.4 96.5 86.7 95.4 98.6 89.4 96.8 82.5 93.2 97.2 76.6\n",
      " 95.9 99.5 95.  81.9 99.7 97.2 99.4 96.8 97.7 87.2]\n",
      "True Positive Rate for 4 : 96.51162790697676\n",
      "True Positive Rate for 9 : 96.80284191829485\n",
      "True Positive Rate for 11 : 93.22638146167557\n",
      "True Positive Rate for 21 : 96.82539682539682\n",
      "Average TP:95.841562028086\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9332315997361625\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 9)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 9)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 9)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278 1.19815844] ; and the std is = [1.42146386 0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 2, 128)\n",
      "[INFO] -- Test Sections:  (13344, 2, 128)\n",
      "[INFO] -- Training Sections:(60059, 2, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 2, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 187736\n",
      "***[RESULT]*** ID Accuracy: 0.9327038369304557\n",
      "***[RESULT]*** ID F1: 93.16\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 74.9  99.7  93.4  89.1  96.5  83.1  95.9  98.9  94.   98.4  70.9  90.9\n",
      "  98.8  74.8  89.6 100.   95.6  93.3 100.   93.2  99.9  99.   95.1  94.6]\n",
      "True Positive Rate for 4 : 96.51162790697676\n",
      "True Positive Rate for 9 : 98.40142095914743\n",
      "True Positive Rate for 11 : 90.9090909090909\n",
      "True Positive Rate for 21 : 99.0079365079365\n",
      "Average TP:96.2075190707879\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9261680441674489\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"rotationRate\",\"userAcceleration\"]\n",
    "mode = \"mag\"\n",
    "ep = 40\n",
    "cga = True # Add gravity to acceleration or not\n",
    "for i in range(5):\n",
    "    results[str(sdt)+\"--\"+str(mode)+\"--\"+str(cga)+\"--\"+str(i)] = eval_id(sdt, mode, ep, cga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['rotationRate', 'userAcceleration']--mag--True--0\": [0.923, 0.9114, 0.9617],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--1\": [0.9314,\n",
       "  0.9242,\n",
       "  0.9616],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--2\": [0.9392, 0.9339, 0.949],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--3\": [0.9389,\n",
       "  0.9332,\n",
       "  0.9584],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--4\": [0.9327,\n",
       "  0.9262,\n",
       "  0.9621],\n",
       " \"['userAcceleration']--mag--True--0\": [0.878, 0.8633, 0.9027],\n",
       " \"['userAcceleration']--mag--True--1\": [0.8872, 0.8761, 0.8893],\n",
       " \"['userAcceleration']--mag--True--2\": [0.8864, 0.8777, 0.8954],\n",
       " \"['userAcceleration']--mag--True--3\": [0.8786, 0.8715, 0.8811],\n",
       " \"['userAcceleration']--mag--True--4\": [0.8829, 0.8676, 0.9006],\n",
       " \"['userAcceleration']--raw--True--0\": [0.9224, 0.9198, 0.9822],\n",
       " \"['userAcceleration']--raw--True--1\": [0.9288, 0.9296, 0.9888],\n",
       " \"['userAcceleration']--raw--True--2\": [0.9277, 0.9244, 0.9796],\n",
       " \"['userAcceleration']--raw--True--3\": [0.9258, 0.924, 0.9831],\n",
       " \"['userAcceleration']--raw--True--4\": [0.9275, 0.9255, 0.992]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 13)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 13)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 13)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.00676741  0.02878308  0.02359966  0.02367904  0.95806826 -0.05104623] ; and the std is = [1.74135109 1.64053436 1.08396877 0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 6, 128)\n",
      "[INFO] -- Test Sections:  (13344, 6, 128)\n",
      "[INFO] -- Training Sections:(60059, 6, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 6, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 449880\n",
      "***[RESULT]*** ID Accuracy: 0.9350269784172662\n",
      "***[RESULT]*** ID F1: 93.34\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 92.9 100.   89.9  84.9 100.   99.2  70.3  69.4  97.4  98.8  98.8  96.8\n",
      " 100.   69.4  91.8 100.   97.  100.  100.   95.   97.9 100.   99.2 100. ]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 98.75666074600356\n",
      "True Positive Rate for 11 : 96.79144385026738\n",
      "True Positive Rate for 21 : 100.0\n",
      "Average TP:98.88702614906774\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9325265689243271\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 13)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 13)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 13)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.00676741  0.02878308  0.02359966  0.02367904  0.95806826 -0.05104623] ; and the std is = [1.74135109 1.64053436 1.08396877 0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 6, 128)\n",
      "[INFO] -- Test Sections:  (13344, 6, 128)\n",
      "[INFO] -- Training Sections:(60059, 6, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 6, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 449880\n",
      "***[RESULT]*** ID Accuracy: 0.9302308153477218\n",
      "***[RESULT]*** ID F1: 92.86999999999999\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 77.2 100.  100.   47.8 100.   98.8  93.4  60.8  98.2 100.  100.   97.\n",
      " 100.   72.5  99.8  99.1  97.6 100.   98.2  99.8  98.2  99.6  99.7 100. ]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 100.0\n",
      "True Positive Rate for 11 : 96.96969696969697\n",
      "True Positive Rate for 21 : 99.60317460317461\n",
      "Average TP:99.1432178932179\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9290414241426904\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 13)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 13)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 13)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.00676741  0.02878308  0.02359966  0.02367904  0.95806826 -0.05104623] ; and the std is = [1.74135109 1.64053436 1.08396877 0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 6, 128)\n",
      "[INFO] -- Test Sections:  (13344, 6, 128)\n",
      "[INFO] -- Training Sections:(60059, 6, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 6, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 449880\n",
      "***[RESULT]*** ID Accuracy: 0.9288818944844125\n",
      "***[RESULT]*** ID F1: 92.69\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 87.1 100.   96.2  38.3 100.  100.   97.2  60.8  96.8  99.1  99.1  98.8\n",
      " 100.   73.3  93.9 100.  100.  100.  100.  100.   99.7  98.   99.8  98. ]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 99.11190053285968\n",
      "True Positive Rate for 11 : 98.75222816399287\n",
      "True Positive Rate for 21 : 98.01587301587301\n",
      "Average TP:98.9700004281814\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9291945175218213\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 13)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 13)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 13)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.00676741  0.02878308  0.02359966  0.02367904  0.95806826 -0.05104623] ; and the std is = [1.74135109 1.64053436 1.08396877 0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 6, 128)\n",
      "[INFO] -- Test Sections:  (13344, 6, 128)\n",
      "[INFO] -- Training Sections:(60059, 6, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 6, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 449880\n",
      "***[RESULT]*** ID Accuracy: 0.9248351318944844\n",
      "***[RESULT]*** ID F1: 92.36\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 84.4 100.   98.2  47.  100.   99.4  53.5  90.4  99.8 100.   99.5  91.1\n",
      " 100.   73.3  94.9 100.   98.4 100.  100.   99.8  99.   99.   99.7  96. ]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 100.0\n",
      "True Positive Rate for 11 : 91.0873440285205\n",
      "True Positive Rate for 21 : 99.0079365079365\n",
      "Average TP:97.52382013411426\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9188192865713979\n",
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: raw -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 13)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 13)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 13)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [ 0.00676741  0.02878308  0.02359966  0.02367904  0.95806826 -0.05104623] ; and the std is = [1.74135109 1.64053436 1.08396877 0.48401853 0.74077811 0.47270486]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 6, 128)\n",
      "[INFO] -- Test Sections:  (13344, 6, 128)\n",
      "[INFO] -- Training Sections:(60059, 6, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 6, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 449880\n",
      "***[RESULT]*** ID Accuracy: 0.9425959232613909\n",
      "***[RESULT]*** ID F1: 93.67\n",
      "***[RESULT]*** ID  Confusion Matrix\n",
      "[ 95.4 100.   96.5  64.8 100.   97.8  85.1  91.   80.   99.8  99.1  95.7\n",
      " 100.   72.2  92.2  97.7  99.2  99.5 100.  100.   99.9  99.   98.2  99.1]\n",
      "True Positive Rate for 4 : 100.0\n",
      "True Positive Rate for 9 : 99.82238010657194\n",
      "True Positive Rate for 11 : 95.72192513368985\n",
      "True Positive Rate for 21 : 99.0079365079365\n",
      "Average TP:98.63806043704957\n",
      "***[RESULT]*** ID Averaged F-1 Score : 0.9417669448883043\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"rotationRate\",\"userAcceleration\"]\n",
    "mode = \"raw\"\n",
    "ep = 40\n",
    "cga = True # Add gravity to acceleration or not\n",
    "for i in range(5):\n",
    "    results[str(sdt)+\"--\"+str(mode)+\"--\"+str(cga)+\"--\"+str(i)] = eval_id(sdt, mode, ep, cga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['rotationRate', 'userAcceleration']--mag--True--0\": [0.923, 0.9114, 0.9617],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--1\": [0.9314,\n",
       "  0.9242,\n",
       "  0.9616],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--2\": [0.9392, 0.9339, 0.949],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--3\": [0.9389,\n",
       "  0.9332,\n",
       "  0.9584],\n",
       " \"['rotationRate', 'userAcceleration']--mag--True--4\": [0.9327,\n",
       "  0.9262,\n",
       "  0.9621],\n",
       " \"['rotationRate', 'userAcceleration']--raw--True--0\": [0.935, 0.9325, 0.9889],\n",
       " \"['rotationRate', 'userAcceleration']--raw--True--1\": [0.9302, 0.929, 0.9914],\n",
       " \"['rotationRate', 'userAcceleration']--raw--True--2\": [0.9289,\n",
       "  0.9292,\n",
       "  0.9897],\n",
       " \"['rotationRate', 'userAcceleration']--raw--True--3\": [0.9248,\n",
       "  0.9188,\n",
       "  0.9752],\n",
       " \"['rotationRate', 'userAcceleration']--raw--True--4\": [0.9426,\n",
       "  0.9418,\n",
       "  0.9864],\n",
       " \"['userAcceleration']--mag--True--0\": [0.878, 0.8633, 0.9027],\n",
       " \"['userAcceleration']--mag--True--1\": [0.8872, 0.8761, 0.8893],\n",
       " \"['userAcceleration']--mag--True--2\": [0.8864, 0.8777, 0.8954],\n",
       " \"['userAcceleration']--mag--True--3\": [0.8786, 0.8715, 0.8811],\n",
       " \"['userAcceleration']--mag--True--4\": [0.8829, 0.8676, 0.9006],\n",
       " \"['userAcceleration']--raw--True--0\": [0.9224, 0.9198, 0.9822],\n",
       " \"['userAcceleration']--raw--True--1\": [0.9288, 0.9296, 0.9888],\n",
       " \"['userAcceleration']--raw--True--2\": [0.9277, 0.9244, 0.9796],\n",
       " \"['userAcceleration']--raw--True--3\": [0.9258, 0.924, 0.9831],\n",
       " \"['userAcceleration']--raw--True--4\": [0.9275, 0.9255, 0.992]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/45305384/5210098\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def eval_id(sdt, mode, ep, cga):\n",
    "\n",
    "    print(\"[INFO] -- Selected sensor data types: \"+str(sdt)+\" -- Mode: \"+str(mode)+\" -- Grav+Acc: \"+str(cga))    \n",
    "    act_labels = ACT_LABELS [0:4]\n",
    "\n",
    "    print(\"[INFO] -- Selected activites: \"+str(act_labels))    \n",
    "    trial_codes = [TRIAL_CODES[act] for act in act_labels]\n",
    "    dt_list = set_data_types(sdt)\n",
    "    dataset = creat_time_series(dt_list, act_labels, trial_codes, mode=mode, labeled=True, combine_grav_acc = cga)\n",
    "    print(\"[INFO] -- Shape of time-Series dataset:\"+str(dataset.shape))    \n",
    "\n",
    "\n",
    "    #*****************\n",
    "    TRAIN_TEST_TYPE = \"trial\" # \"subject\" or \"trial\"\n",
    "    #*****************\n",
    "\n",
    "    if TRAIN_TEST_TYPE == \"subject\":\n",
    "        test_ids = [4,9,11,21]\n",
    "        print(\"[INFO] -- Test IDs: \"+str(test_ids))\n",
    "        test_ts = dataset.loc[(dataset['id'].isin(test_ids))]\n",
    "        train_ts = dataset.loc[~(dataset['id'].isin(test_ids))]\n",
    "    else:\n",
    "        test_trail = [11,12,13,14,15,16]  \n",
    "        print(\"[INFO] -- Test Trials: \"+str(test_trail))\n",
    "        test_ts = dataset.loc[(dataset['trial'].isin(test_trail))]\n",
    "        train_ts = dataset.loc[~(dataset['trial'].isin(test_trail))]\n",
    "\n",
    "    print(\"[INFO] -- Shape of Train Time-Series :\"+str(train_ts.shape))\n",
    "    print(\"[INFO] -- Shape of Test Time-Series :\"+str(test_ts.shape))\n",
    "    \n",
    "#     print(\"___________Train_VAL____________\")\n",
    "#     val_trail = [11,12,13,14,15,16]\n",
    "#     val_ts = train_ts.loc[(train_ts['trial'].isin(val_trail))]\n",
    "#     train_ts = train_ts.loc[~(train_ts['trial'].isin(val_trail))]\n",
    "#     print(\"[INFO] -- Training Time-Series :\"+str(train_ts.shape))\n",
    "#     print(\"[INFO] -- Validation Time-Series :\"+str(val_ts.shape)) \n",
    "    print(\"___________________________________________________\")\n",
    "\n",
    "    ## This Variable Defines the Size of Sliding Window\n",
    "    ## ( e.g. 100 means in each snapshot we just consider 100 consecutive observations of each sensor) \n",
    "    w = 128 # 50 Equals to 1 second for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "    ## Here We Choose Step Size for Building Diffrent Snapshots from Time-Series Data\n",
    "    ## ( smaller step size will increase the amount of the instances and higher computational cost may be incurred )\n",
    "    s = 10\n",
    "    train_data, act_train, id_train, train_mean, train_std = ts_to_secs(train_ts.copy(),\n",
    "                                                                       w,\n",
    "                                                                       s,\n",
    "                                                                       standardize = True)\n",
    "    \n",
    "   \n",
    "    s = 10\n",
    "    test_data, act_test, id_test, test_mean, test_std = ts_to_secs(test_ts.copy(),\n",
    "                                                                  w,\n",
    "                                                                  s,\n",
    "                                                                  standardize = True,\n",
    "                                                                  mean = train_mean, \n",
    "                                                                  std = train_std)\n",
    "    \n",
    "    print(\"[INFO] -- Training Sections: \"+str(train_data.shape))\n",
    "    print(\"[INFO] -- Test Sections:  \"+str(test_data.shape))\n",
    "\n",
    "\n",
    "    id_train_labels = to_categorical(id_train)\n",
    "    id_test_labels = to_categorical(id_test)\n",
    "    \n",
    "    act_train_labels = to_categorical(act_train)\n",
    "    act_test_labels = to_categorical(act_test)\n",
    "    \n",
    "    ## Here we add an extra dimension to the datasets just to be ready for using with Convolution2D\n",
    "    train_data = np.expand_dims(train_data,axis=3)\n",
    "    print(\"[INFO] -- Training Sections:\"+str(train_data.shape))\n",
    "\n",
    "    test_data = np.expand_dims(test_data,axis=3)\n",
    "    print(\"[INFO] -- Test Sections:\"+str(test_data.shape))\n",
    "\n",
    "    height = train_data.shape[1]\n",
    "    width = train_data.shape[2]\n",
    "\n",
    "    id_class_numbers = 24\n",
    "    act_class_numbers = 4\n",
    "    fm = (2,5)\n",
    "\n",
    "    print(\"___________________________________________________\")\n",
    "    ## Callbacks\n",
    "    #eval_metric= \"val_acc\"\n",
    "    eval_metric= \"val_f1_metric\"    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor=eval_metric, mode='max', patience = 7)\n",
    "    filepath=\"MID.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor=eval_metric, verbose=0, save_best_only=True, mode='max')\n",
    "    callbacks_list = [early_stop,\n",
    "                      checkpoint\n",
    "                     ]\n",
    "    ## Callbacks\n",
    "    eval_id = Estimator.build(height, width, id_class_numbers, name =\"EVAL_ID\", fm=fm, act_func=\"softmax\",hid_act_func=\"relu\")\n",
    "    eval_id.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc', f1_metric])\n",
    "    print(\"Model Size = \"+str(eval_id.count_params()))\n",
    "\n",
    "    eval_id.fit(train_data, id_train_labels,\n",
    "                validation_data = (test_data, id_test_labels),\n",
    "                epochs = ep,\n",
    "                batch_size = 128,\n",
    "                verbose = 0,\n",
    "                class_weight = get_class_weights(np.argmax(id_train_labels,axis=1)),\n",
    "                callbacks = callbacks_list\n",
    "               )\n",
    "\n",
    "    eval_id.load_weights(\"MID.best.hdf5\")\n",
    "    eval_id.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc',f1_metric])\n",
    "\n",
    "    result1 = eval_id.evaluate(test_data, id_test_labels, verbose = 2)\n",
    "    id_acc = result1[1]\n",
    "    print(\"***[RESULT]*** ID Accuracy: \"+str(id_acc))\n",
    "    rf1 = result1[2].round(4)*100\n",
    "    print(\"***[RESULT]*** ID F1: \"+str(rf1))\n",
    "    \n",
    "    preds = eval_id.predict(test_data)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    conf_mat = confusion_matrix(np.argmax(id_test_labels, axis=1), preds)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"***[RESULT]*** ID  Confusion Matrix\")\n",
    "    print((np.array(conf_mat).diagonal()).round(3)*100)  \n",
    "    \n",
    "    d_test_ids = [4,9,11,21]\n",
    "    to_avg = 0\n",
    "    for i in range(len(d_test_ids)):\n",
    "        true_positive = conf_mat[d_test_ids[i],d_test_ids[i]]\n",
    "        print(\"True Positive Rate for \"+str(d_test_ids[i])+\" : \"+str(true_positive*100))\n",
    "        to_avg+=true_positive\n",
    "    atp = to_avg/len(d_test_ids)    \n",
    "    print(\"Average TP:\"+str(atp*100))    \n",
    "    \n",
    "    f1id = f1_score(np.argmax(id_test_labels, axis=1), preds, average=None).mean()\n",
    "    print(\"***[RESULT]*** ID Averaged F-1 Score : \"+str(f1id))\n",
    "    \n",
    "    return [round(id_acc,4), round(f1id,4), round(atp,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['rotationRate', 'userAcceleration'] -- Mode: mag -- Grav+Acc: True\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog']\n",
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n",
      "[INFO] -- Shape of time-Series dataset:(767660, 9)\n",
      "[INFO] -- Test Trials: [11, 12, 13, 14, 15, 16]\n",
      "[INFO] -- Shape of Train Time-Series :(621973, 9)\n",
      "[INFO] -- Shape of Test Time-Series :(145687, 9)\n",
      "___________________________________________________\n",
      "[INFO] -- Training Data has been standardized: the mean is = [2.20896278 1.19815844] ; and the std is = [1.42146386 0.70139403]\n",
      "[INFO] -- Test/Val Data has been standardized\n",
      "[INFO] -- Training Sections: (60059, 2, 128)\n",
      "[INFO] -- Test Sections:  (13344, 2, 128)\n",
      "[INFO] -- Training Sections:(60059, 2, 128, 1)\n",
      "[INFO] -- Test Sections:(13344, 2, 128, 1)\n",
      "___________________________________________________\n",
      "Model Size = 223896\n"
     ]
    }
   ],
   "source": [
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "## attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "sdt = [\"rotationRate\",\"userAcceleration\"]\n",
    "mode = \"mag\"\n",
    "ep = 40\n",
    "cga = True # Add gravity to acceleration or not\n",
    "for i in range(5):\n",
    "    results[str(sdt)+\"-2D-\"+str(mode)+\"--\"+str(cga)+\"--\"+str(i)] = eval_id(sdt, mode, ep, cga)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

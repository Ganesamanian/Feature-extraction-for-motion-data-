{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Start...\n",
      "--> Building Training and Test Datasets...\n",
      "----> Data subjects information is imported.\n",
      "--> Shape of Training Time-Seires: (621973, 17)\n",
      "--> Shape of Test Time-Series: (145687, 17)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "##_____________________________\n",
    "\n",
    "def get_ds_infos():\n",
    "    ## 0:Code, 1:Weight, 2:Height, 3:Age, 4:Gender\n",
    "    dss = np.genfromtxt(\"data_subjects_info.csv\",delimiter=',')\n",
    "    dss = dss[1:]\n",
    "    print(\"----> Data subjects information is imported.\")\n",
    "    return dss\n",
    "##____________\n",
    "\n",
    "def creat_time_series(num_features, num_act_labels, num_gen_labels, label_codes, trial_codes):\n",
    "    dataset_columns = num_features+num_act_labels+num_gen_labels\n",
    "    ds_list = get_ds_infos()\n",
    "    train_data = np.zeros((0,dataset_columns))\n",
    "    test_data = np.zeros((0,dataset_columns))\n",
    "    for i, sub_id in enumerate(ds_list[:,0]):\n",
    "        for j, act in enumerate(label_codes):\n",
    "            for trial in trial_codes[act]:\n",
    "                fname = 'A_DeviceMotion_data/'+act+'_'+str(trial)+'/sub_'+str(int(sub_id))+'.csv'\n",
    "                raw_data = pd.read_csv(fname)\n",
    "                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n",
    "                unlabel_data = raw_data.values\n",
    "                label_data = np.zeros((len(unlabel_data), dataset_columns))\n",
    "                label_data[:,:-(num_act_labels + num_gen_labels)] = unlabel_data\n",
    "                label_data[:,label_codes[act]] = 1\n",
    "                label_data[:,-(num_gen_labels)] = int(ds_list[i,4])\n",
    "                ## We consider long trials as training dataset and short trials as test dataset\n",
    "                if trial > 10:\n",
    "                    test_data = np.append(test_data, label_data, axis = 0)\n",
    "                else:    \n",
    "                    train_data = np.append(train_data, label_data, axis = 0)\n",
    "    return train_data , test_data\n",
    "#________________________________\n",
    "\n",
    "\n",
    "print(\"--> Start...\")\n",
    "## Here we set parameter to build labeld time-series from dataset of \"(A)DeviceMotion_data\"\n",
    "num_features = 12 # attitude(roll, pitch, yaw); gravity(x, y, z); rotationRate(x, y, z); userAcceleration(x,y,z)\n",
    "num_act_labels = 4 # dws, ups, wlk, jog\n",
    "num_gen_labels = 1 # 0/1(female/male)\n",
    "label_codes = {\"dws\":num_features, \"ups\":num_features+1, \"wlk\":num_features+2, \"jog\":num_features+3}\n",
    "trial_codes = {\"dws\":[1,2,11], \"ups\":[3,4,12], \"wlk\":[7,8,15], \"jog\":[9,16]}    \n",
    "## Calling 'creat_time_series()' to build time-series\n",
    "print(\"--> Building Training and Test Datasets...\")\n",
    "train_ts, test_ts = creat_time_series(num_features, num_act_labels, num_gen_labels, label_codes, trial_codes)\n",
    "print(\"--> Shape of Training Time-Seires:\", train_ts.shape)\n",
    "print(\"--> Shape of Test Time-Series:\", test_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Sectioning Training and Test datasets: shape of each section will be: ( 12 x 50 )\n",
      "----> Training Data has been standardized:\n",
      " the mean is =  -0.016953116747561597  ; and the std is =  0.8714768261722003\n",
      "----> Test Data has been standardized\n",
      "--> Shape of Training Sections: (61726, 12, 50)\n",
      "--> Shape of Test Sections: (14094, 12, 50)\n"
     ]
    }
   ],
   "source": [
    "def time_series_to_section(dataset, num_act_labels, num_gen_labels, sliding_window_size, step_size_of_sliding_window, standardize = False, **options):\n",
    "    data = dataset[: , 0:-(num_act_labels+num_gen_labels)]\n",
    "    act_labels = dataset[: , -(num_act_labels+num_gen_labels):-(num_gen_labels)]\n",
    "    gen_labels = dataset[: , -(num_gen_labels)]\n",
    "    mean = 0\n",
    "    std = 1\n",
    "    \n",
    "    if standardize:\n",
    "        ## Standardize each sensorâ€™s data to have a zero mean and unity standard deviation.\n",
    "        ## As usual, we normalize test dataset by training dataset's parameters \n",
    "        if options:\n",
    "            mean = options.get(\"mean\")\n",
    "            std = options.get(\"std\")\n",
    "            print(\"----> Test Data has been standardized\")\n",
    "        else:\n",
    "            mean = data.mean(axis=0)\n",
    "            std = data.std(axis=0)\n",
    "            print(\"----> Training Data has been standardized:\\n the mean is = \",str(mean.mean()),\" ; and the std is = \",str(std.mean()))            \n",
    "  \n",
    "        data -= mean\n",
    "        data /= std\n",
    "    else:\n",
    "        print(\"----> Without Standardization.....\")\n",
    "\n",
    "    ## We want the Rows of matrices show each Feature and the Columns show time points.\n",
    "    data = data.T\n",
    "            \n",
    "    size_features = data.shape[0]\n",
    "    size_data = data.shape[1]\n",
    "    number_of_secs = round(((size_data - sliding_window_size)/step_size_of_sliding_window))\n",
    "            \n",
    "    ##  Create a 3D matrix for Storing Snapshots  \n",
    "    secs_data = np.zeros((number_of_secs , size_features , sliding_window_size ))\n",
    "    act_secs_labels = np.zeros((number_of_secs, 4))\n",
    "    gen_secs_labels = np.zeros(number_of_secs)\n",
    "    \n",
    "    k=0    \n",
    "    for i in range(0 ,(size_data)-sliding_window_size  , step_size_of_sliding_window):\n",
    "        j = i // step_size_of_sliding_window\n",
    "        if(j>=number_of_secs):\n",
    "            break\n",
    "        if(gen_labels[i] != gen_labels[i+sliding_window_size-1]): \n",
    "            continue\n",
    "        if(not (act_labels[i] == act_labels[i+sliding_window_size-1]).all()): \n",
    "            continue    \n",
    "        secs_data[k] = data[0:size_features, i:i+sliding_window_size]\n",
    "        act_secs_labels[k] = act_labels[i].astype(int)\n",
    "        gen_secs_labels[k] = gen_labels[i].astype(int)\n",
    "        k = k+1\n",
    "    secs_data = secs_data[0:k]\n",
    "    act_secs_labels = act_secs_labels[0:k]\n",
    "    gen_secs_labels = gen_secs_labels[0:k]\n",
    "    \n",
    "    return secs_data, act_secs_labels, gen_secs_labels, mean, std\n",
    "##________________________________________________________________\n",
    "\n",
    "\n",
    "## This Variable Defines the Size of Sliding Window\n",
    "## ( e.g. 100 means in each snapshot we just consider 100 consecutive observations of each sensor) \n",
    "sliding_window_size = 50 # 50 Equals to 1 second for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "## Here We Choose Step Size for Building Diffrent Snapshots from Time-Series Data\n",
    "## ( smaller step size will increase the amount of the instances and higher computational cost may be incurred )\n",
    "step_size_of_sliding_window = 10 \n",
    "print(\"--> Sectioning Training and Test datasets: shape of each section will be: (\",num_features,\"x\",sliding_window_size,\")\")\n",
    "train_data, act_train_labels, gen_train_labels, train_mean, train_std = time_series_to_section(train_ts.copy(),\n",
    "                                                                                               num_act_labels,\n",
    "                                                                                               num_gen_labels,\n",
    "                                                                                               sliding_window_size,\n",
    "                                                                                               step_size_of_sliding_window,\n",
    "                                                                                               standardize = True)\n",
    "\n",
    "test_data, act_test_labels, gen_test_labels, test_mean, test_std = time_series_to_section(test_ts.copy(),\n",
    "                                                                                          num_act_labels,\n",
    "                                                                                          num_gen_labels,\n",
    "                                                                                          sliding_window_size,\n",
    "                                                                                          step_size_of_sliding_window,\n",
    "                                                                                          standardize = True,\n",
    "                                                                                          mean = train_mean, \n",
    "                                                                                          std = train_std)\n",
    "print(\"--> Shape of Training Sections:\", train_data.shape)\n",
    "print(\"--> Shape of Test Sections:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Shape of Training Sections: (61726, 12, 50, 1)\n",
      "--> Shape of Test Sections: (14094, 12, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils \n",
    "##______________________________\n",
    "## Here we add an extra dimension to the datasets just to be ready for using with Convolution2D\n",
    "train_data = np.expand_dims(train_data,axis=3)\n",
    "test_data = np.expand_dims(test_data,axis=3)\n",
    "print(\"--> Shape of Training Sections:\", train_data.shape)\n",
    "print(\"--> Shape of Test Sections:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "61726/61726 [==============================] - 43s 689us/step - loss: 0.6050 - ACT_loss: 0.3734 - GEN_loss: 0.2316 - ACT_acc: 0.8736 - GEN_acc: 0.9026\n",
      "Epoch 2/20\n",
      "61726/61726 [==============================] - 42s 674us/step - loss: 0.2919 - ACT_loss: 0.1847 - GEN_loss: 0.1072 - ACT_acc: 0.9438 - GEN_acc: 0.9592\n",
      "Epoch 3/20\n",
      "61726/61726 [==============================] - 42s 678us/step - loss: 0.2270 - ACT_loss: 0.1506 - GEN_loss: 0.0763 - ACT_acc: 0.9536 - GEN_acc: 0.9721\n",
      "Epoch 4/20\n",
      "61726/61726 [==============================] - 42s 679us/step - loss: 0.1932 - ACT_loss: 0.1306 - GEN_loss: 0.0625 - ACT_acc: 0.9593 - GEN_acc: 0.9773\n",
      "Epoch 5/20\n",
      "61726/61726 [==============================] - 42s 682us/step - loss: 0.1695 - ACT_loss: 0.1167 - GEN_loss: 0.0528 - ACT_acc: 0.9629 - GEN_acc: 0.9807\n",
      "Epoch 6/20\n",
      "61726/61726 [==============================] - 42s 679us/step - loss: 0.1520 - ACT_loss: 0.1063 - GEN_loss: 0.0457 - ACT_acc: 0.9656 - GEN_acc: 0.9833\n",
      "Epoch 7/20\n",
      "61726/61726 [==============================] - 42s 676us/step - loss: 0.1412 - ACT_loss: 0.0982 - GEN_loss: 0.0430 - ACT_acc: 0.9683 - GEN_acc: 0.9846\n",
      "Epoch 8/20\n",
      "61726/61726 [==============================] - 42s 681us/step - loss: 0.1298 - ACT_loss: 0.0923 - GEN_loss: 0.0376 - ACT_acc: 0.9693 - GEN_acc: 0.9861\n",
      "Epoch 9/20\n",
      "61726/61726 [==============================] - 42s 679us/step - loss: 0.1240 - ACT_loss: 0.0871 - GEN_loss: 0.0369 - ACT_acc: 0.9709 - GEN_acc: 0.9866\n",
      "Epoch 10/20\n",
      "61726/61726 [==============================] - 42s 674us/step - loss: 0.1160 - ACT_loss: 0.0822 - GEN_loss: 0.0338 - ACT_acc: 0.9728 - GEN_acc: 0.9876\n",
      "Epoch 11/20\n",
      "61726/61726 [==============================] - 42s 688us/step - loss: 0.1105 - ACT_loss: 0.0797 - GEN_loss: 0.0308 - ACT_acc: 0.9741 - GEN_acc: 0.9890\n",
      "Epoch 12/20\n",
      "61726/61726 [==============================] - 42s 679us/step - loss: 0.1091 - ACT_loss: 0.0758 - GEN_loss: 0.0333 - ACT_acc: 0.9744 - GEN_acc: 0.9883\n",
      "Epoch 13/20\n",
      "61726/61726 [==============================] - 42s 675us/step - loss: 0.1001 - ACT_loss: 0.0719 - GEN_loss: 0.0282 - ACT_acc: 0.9754 - GEN_acc: 0.9897\n",
      "Epoch 14/20\n",
      "61726/61726 [==============================] - 42s 675us/step - loss: 0.0975 - ACT_loss: 0.0697 - GEN_loss: 0.0277 - ACT_acc: 0.9764 - GEN_acc: 0.9902\n",
      "Epoch 15/20\n",
      "61726/61726 [==============================] - 41s 672us/step - loss: 0.0916 - ACT_loss: 0.0665 - GEN_loss: 0.0251 - ACT_acc: 0.9777 - GEN_acc: 0.9910\n",
      "Epoch 16/20\n",
      "61726/61726 [==============================] - 42s 679us/step - loss: 0.0910 - ACT_loss: 0.0653 - GEN_loss: 0.0257 - ACT_acc: 0.9778 - GEN_acc: 0.9911\n",
      "Epoch 17/20\n",
      "61726/61726 [==============================] - 41s 672us/step - loss: 0.0862 - ACT_loss: 0.0630 - GEN_loss: 0.0232 - ACT_acc: 0.9787 - GEN_acc: 0.9916\n",
      "Epoch 18/20\n",
      "61726/61726 [==============================] - 41s 672us/step - loss: 0.0811 - ACT_loss: 0.0582 - GEN_loss: 0.0229 - ACT_acc: 0.9801 - GEN_acc: 0.9920\n",
      "Epoch 19/20\n",
      "61726/61726 [==============================] - 42s 674us/step - loss: 0.0817 - ACT_loss: 0.0604 - GEN_loss: 0.0213 - ACT_acc: 0.9794 - GEN_acc: 0.9920\n",
      "Epoch 20/20\n",
      "61726/61726 [==============================] - 42s 673us/step - loss: 0.0773 - ACT_loss: 0.0561 - GEN_loss: 0.0212 - ACT_acc: 0.9809 - GEN_acc: 0.9923\n"
     ]
    }
   ],
   "source": [
    "##***@@@ This Will Be the ESTIMATOR @@@***##\n",
    "## Here we set up the parameters for MTCNN\n",
    "num_train, height, width, channel = train_data.shape\n",
    "metrics = ['acc']\n",
    "## Activity Recognition\n",
    "act_last_layer_dim = num_act_labels\n",
    "act_loss_func = \"categorical_crossentropy\"\n",
    "act_activation_func = 'softmax'\n",
    "## Gender Classification\n",
    "gen_last_layer_dim = num_gen_labels \n",
    "gen_loss_func = \"binary_crossentropy\"\n",
    "gen_activation_func = 'sigmoid'\n",
    "## Training Phase\n",
    "batch_size = 64\n",
    "num_of_epochs = 20\n",
    "verbosity = 1\n",
    "## MTCNN\n",
    "kernel_size_1 = 5\n",
    "kernel_size_2 = 3\n",
    "pool_size_1 = 2\n",
    "pool_size_2 = 3  \n",
    "conv_depth_1 = 50 \n",
    "conv_depth_2 = 40 \n",
    "conv_depth_3 = 20 \n",
    "drop_prob_1 = 0.2 \n",
    "drop_prob_2 = 0.4 \n",
    "hidden_size = 400 \n",
    "\n",
    "## Note that: because each section of time-series is a matrix, we use Convolution2D.\n",
    "## On the other side: because each row of the matrix correspond to one feature of\n",
    "##   time-series, so we use a (1,k) kernel to convolve the data points of each row with \n",
    "##   just that row's data points\n",
    "inp = Input(shape=(height, width,1))     \n",
    "conv_0 = Convolution2D(conv_depth_1, (1 , kernel_size_1), padding='valid', activation='relu')(inp)\n",
    "conv_1 = Convolution2D(conv_depth_1, (1 , kernel_size_2), padding='same', activation='relu')(conv_0)\n",
    "dense_1 = Dense(conv_depth_1, activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(1, pool_size_1))(dense_1)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "conv_2 = Convolution2D(conv_depth_2, (1 , kernel_size_1), padding='valid', activation='relu')(drop_1)\n",
    "dense_2 = Dense(conv_depth_2, activation='relu')(conv_2)\n",
    "pool_2 = MaxPooling2D(pool_size=(1, pool_size_2))(dense_2)\n",
    "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "\n",
    "conv_3 = Convolution2D(conv_depth_3, (1 , kernel_size_2), padding='valid', activation='relu')(drop_2)\n",
    "drop_3 = Dropout(drop_prob_1)(conv_3)\n",
    "\n",
    "flat = Flatten()(drop_3)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_4 = Dropout(drop_prob_2)(hidden)\n",
    "\n",
    "out1 = Dense(act_last_layer_dim, activation= act_activation_func, name = \"ACT\")(drop_4)\n",
    "out2 = Dense(gen_last_layer_dim, activation= gen_activation_func, name = \"GEN\")(drop_4)\n",
    "\n",
    "act_gen_model = Model(inputs=inp, outputs=[out1,out2]) \n",
    "\n",
    "act_gen_model.compile(loss=[act_loss_func, gen_loss_func], \n",
    "          optimizer='adam', \n",
    "          metrics=metrics)\n",
    "\n",
    "history = act_gen_model.fit(train_data, [act_train_labels, gen_train_labels],                \n",
    "              batch_size = batch_size,\n",
    "              epochs = num_of_epochs,\n",
    "              verbose = verbosity) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14094/14094 [==============================] - 4s 259us/step\n",
      "--> Evaluation on Test Dataset:\n",
      "**** Accuracy for Activity Recognition task is:  0.951113949172866\n",
      "**** Accuracy for Gender Classification task is:  0.9523910883894977\n"
     ]
    }
   ],
   "source": [
    "results_1 = act_gen_model.evaluate(test_data, [act_test_labels, gen_test_labels],\n",
    "                                 verbose = verbosity)\n",
    "\n",
    "print(\"--> Evaluation on Test Dataset:\")\n",
    "print(\"**** Accuracy for Activity Recognition task is: \", results_1[3])\n",
    "print(\"**** Accuracy for Gender Classification task is: \", results_1[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Saved MTCNN and its weights to disk!\n"
     ]
    }
   ],
   "source": [
    "## serialize model to JSON and save MTCNN model\n",
    "act_gen_model_json = act_gen_model.to_json()\n",
    "with open(\"act_gen_model_1_ms_t.json\", \"w\") as json_file:\n",
    "    json_file.write(act_gen_model_json)\n",
    "## serialize weights to HDF5 and save learned weights\n",
    "act_gen_model.save_weights(\"act_gen_weights_1_ms_t.h5\")\n",
    "print(\"--> Saved MTCNN and its weights to disk!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##***@@@ This Will Be the NEUTRALIZER @@@***##\n",
    "import keras.backend as K\n",
    "def gen_equ_loss_func(y_true, y_pred):\n",
    "    loss = K.mean(K.abs(0.5 - y_pred))\n",
    "    return loss\n",
    "##____________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##***@@@ This Will Be the GUARDIAN @@@***##\n",
    "## Here we set up the Autoencoder\n",
    "ae_inp_size = height*width\n",
    "ae_input = Input(shape=(height, width,1))\n",
    "x = Reshape((ae_inp_size,), input_shape=((height,width,1)))(ae_input)\n",
    "x = Dense(ae_inp_size, activation='linear')(x)\n",
    "\n",
    "encoded = Dense(ae_inp_size//2, activation='relu')(x)\n",
    "encoded = Dense(ae_inp_size//4, activation='relu')(encoded)\n",
    "\n",
    "y = Dense(ae_inp_size//8, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(ae_inp_size//4, activation='relu')(y)\n",
    "decoded = Dense(ae_inp_size//2, activation='relu')(decoded)\n",
    "\n",
    "z = Dense(ae_inp_size, activation='linear')(decoded)\n",
    "z = Reshape((height,width,1), input_shape=(ae_inp_size,))(z)\n",
    "ae_model = Model(ae_input, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "61726/61726 [==============================] - 35s 566us/step - loss: 0.6287 - model_1_loss_1: 0.5168 - model_1_loss_2: 0.1119 - model_1_acc_1: 0.8255 - model_1_acc_2: 0.50987s - loss: 0.675\n",
      "Epoch 2/20\n",
      "61726/61726 [==============================] - 35s 561us/step - loss: 0.3573 - model_1_loss_1: 0.2741 - model_1_loss_2: 0.0832 - model_1_acc_1: 0.9285 - model_1_acc_2: 0.5108\n",
      "Epoch 3/20\n",
      "61726/61726 [==============================] - 35s 564us/step - loss: 0.3199 - model_1_loss_1: 0.2477 - model_1_loss_2: 0.0722 - model_1_acc_1: 0.9369 - model_1_acc_2: 0.5102\n",
      "Epoch 4/20\n",
      "61726/61726 [==============================] - 35s 563us/step - loss: 0.2899 - model_1_loss_1: 0.2235 - model_1_loss_2: 0.0664 - model_1_acc_1: 0.9426 - model_1_acc_2: 0.50947s - loss: 0.2855 - model_1_lo - ETA: 1s - loss: 0.2902 - model_1_loss_1: 0.2238 - model_1_loss_2: 0.0664 - model_1_acc_1: 0.9424 -\n",
      "Epoch 5/20\n",
      "61726/61726 [==============================] - 35s 565us/step - loss: 0.2723 - model_1_loss_1: 0.2065 - model_1_loss_2: 0.0658 - model_1_acc_1: 0.9468 - model_1_acc_2: 0.5062\n",
      "Epoch 6/20\n",
      "61726/61726 [==============================] - 35s 574us/step - loss: 0.2754 - model_1_loss_1: 0.2119 - model_1_loss_2: 0.0635 - model_1_acc_1: 0.9450 - model_1_acc_2: 0.50706s - loss: 0.2733 - model_1_loss_1: 0.2097 - model_1_loss_2: 0. - ETA: 2s - loss: 0.2739 - model_1_loss_1: 0.2105 - model_1_loss_2: 0.0634 - model_1_acc_1: 0.9454 - model - ETA: 1s - loss: 0.2747 - model_1_loss_1: 0.2113 - model_1_loss_2: 0.0634 - model_1_acc_1: 0.\n",
      "Epoch 7/20\n",
      "61726/61726 [==============================] - 34s 559us/step - loss: 0.2614 - model_1_loss_1: 0.1985 - model_1_loss_2: 0.0629 - model_1_acc_1: 0.9498 - model_1_acc_2: 0.51024s - loss: 0.2632 - model_1_loss_1: 0.2002 - model_1_loss_2: 0.0631 - ETA: 1s - loss: 0.2608 - model_1_loss_1: 0.1979 - model_1_loss_2: 0.0629 - model_1_acc_1: 0.9499 - mo\n",
      "Epoch 8/20\n",
      "61726/61726 [==============================] - 35s 561us/step - loss: 0.2527 - model_1_loss_1: 0.1917 - model_1_loss_2: 0.0610 - model_1_acc_1: 0.9495 - model_1_acc_2: 0.5081\n",
      "Epoch 9/20\n",
      "61726/61726 [==============================] - 35s 564us/step - loss: 0.2397 - model_1_loss_1: 0.1793 - model_1_loss_2: 0.0603 - model_1_acc_1: 0.9541 - model_1_acc_2: 0.51061s - loss: 0.2395 - model_1_loss_1: 0.1791 - model_1_loss_2: 0.0604 - model_1_acc_1: 0.954\n",
      "Epoch 10/20\n",
      "61726/61726 [==============================] - 35s 565us/step - loss: 0.2336 - model_1_loss_1: 0.1738 - model_1_loss_2: 0.0598 - model_1_acc_1: 0.9545 - model_1_acc_2: 0.5098\n",
      "Epoch 11/20\n",
      "61726/61726 [==============================] - 35s 562us/step - loss: 0.2210 - model_1_loss_1: 0.1615 - model_1_loss_2: 0.0595 - model_1_acc_1: 0.9580 - model_1_acc_2: 0.50808s - loss: 0.2208 - model_1_loss_1: 0.1614 - model_1_loss_2: 0.0593 - model_1_acc_1: 0.9576 - model_1_acc_2 - ETA: 7s - los\n",
      "Epoch 12/20\n",
      "61726/61726 [==============================] - 35s 563us/step - loss: 0.2258 - model_1_loss_1: 0.1667 - model_1_loss_2: 0.0590 - model_1_acc_1: 0.9565 - model_1_acc_2: 0.51018s - loss: 0.2236 - model_1_loss_1: 0.1641 - model_1_loss_2: 0.0594 - model_1_acc_1: 0.9573 - m - ETA: 6s - loss: 0.2236 -\n",
      "Epoch 13/20\n",
      "61726/61726 [==============================] - 35s 566us/step - loss: 0.2147 - model_1_loss_1: 0.1564 - model_1_loss_2: 0.0583 - model_1_acc_1: 0.9579 - model_1_acc_2: 0.5086\n",
      "Epoch 14/20\n",
      "61726/61726 [==============================] - 35s 561us/step - loss: 0.2105 - model_1_loss_1: 0.1530 - model_1_loss_2: 0.0576 - model_1_acc_1: 0.9603 - model_1_acc_2: 0.5080\n",
      "Epoch 15/20\n",
      "61726/61726 [==============================] - 35s 562us/step - loss: 0.2062 - model_1_loss_1: 0.1487 - model_1_loss_2: 0.0575 - model_1_acc_1: 0.9603 - model_1_acc_2: 0.50975s - loss: 0.2035 - model_1_l\n",
      "Epoch 16/20\n",
      "61726/61726 [==============================] - 35s 567us/step - loss: 0.2016 - model_1_loss_1: 0.1447 - model_1_loss_2: 0.0569 - model_1_acc_1: 0.9612 - model_1_acc_2: 0.51094s - loss: 0.2026 - model_1_loss_1: 0.1456 - model_1_loss_2: 0.0570 - model_1_acc_1: 0.9609 - model_1_acc_2: 0.511 - ETA: 4s - loss: 0.2025 - model_1_loss_1: 0.1455 - model_1_loss_ - ETA: 0s - loss: 0.2016 - model_1_loss_1: 0.1447 - model_1_loss_2: 0.0569 - model_1_acc_1: 0.9614 - model_1_\n",
      "Epoch 17/20\n",
      "61726/61726 [==============================] - 34s 559us/step - loss: 0.2007 - model_1_loss_1: 0.1445 - model_1_loss_2: 0.0562 - model_1_acc_1: 0.9613 - model_1_acc_2: 0.5100\n",
      "Epoch 18/20\n",
      "61726/61726 [==============================] - 35s 563us/step - loss: 0.1967 - model_1_loss_1: 0.1406 - model_1_loss_2: 0.0561 - model_1_acc_1: 0.9621 - model_1_acc_2: 0.51125s - loss: 0.1958 - model_1_l\n",
      "Epoch 19/20\n",
      "61726/61726 [==============================] - 35s 565us/step - loss: 0.1932 - model_1_loss_1: 0.1374 - model_1_loss_2: 0.0558 - model_1_acc_1: 0.9626 - model_1_acc_2: 0.5088\n",
      "Epoch 20/20\n",
      "61726/61726 [==============================] - 35s 566us/step - loss: 0.1857 - model_1_loss_1: 0.1298 - model_1_loss_2: 0.0559 - model_1_acc_1: 0.9659 - model_1_acc_2: 0.51073s - loss: 0.1861 - model_1_loss_1: 0.1300 - model_1_loss_2: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fa83e10f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##***@@@ This Will Be the The Final GEN @@@***##\n",
    "## Here we freeze the weights of the MTCNN layers and attach the output of \n",
    "## deep autoencoder to the input of the MTCNN to build the GEN neural network. \n",
    "act_gen_model.trainable = False\n",
    "dp = ae_model(ae_input)\n",
    "dp = act_gen_model(dp)\n",
    "dp_model = Model(inputs=ae_input, outputs=dp)\n",
    "\n",
    "dp_model.compile(loss=[act_loss_func, gen_equ_loss_func], \n",
    "                 optimizer='adam',\n",
    "                 metrics=metrics)\n",
    "\n",
    "num_of_epochs = 20\n",
    "dp_model.fit(train_data , [act_train_labels, gen_train_labels],\n",
    "                epochs = num_of_epochs,\n",
    "                batch_size = batch_size,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14094/14094 [==============================] - 3s 243us/step\n",
      "@@@@ Transformed Test ACT acc:  0.938910174516984\n",
      "@@@@ Transformed Test GEN acc:  0.4957428693082022\n"
     ]
    }
   ],
   "source": [
    "tr_test_data = ae_model.predict(test_data)\n",
    "results_2 = act_gen_model.evaluate(tr_test_data, [act_test_labels, gen_test_labels])\n",
    "print(\"@@@@ Transformed Test ACT acc: \", results_2[3])\n",
    "print(\"@@@@ Transformed Test GEN acc: \", results_2[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
